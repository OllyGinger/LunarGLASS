
Top IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer
@uiv4 = external addrspace(2) constant <4 x i32>
@ub = external addrspace(2) constant i1

define fastcc void @main() {
entry:
  %gl_FragColor129 = alloca <4 x float>
  %gl_FragColor128 = alloca <4 x float>
  %gl_FragColor = alloca <4 x float>
  %f = alloca float
  %b = alloca i1
  %i = alloca i32
  %v = alloca <4 x float>
  %0 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v2 = call <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float> %0)
  store <4 x float> %v2, <4 x float>* %v
  %1 = load <4 x float>* %v
  %v3 = call <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float> %1)
  %2 = load <4 x float>* %v
  %v4 = fadd <4 x float> %2, %v3
  store <4 x float> %v4, <4 x float>* %v
  %3 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %4 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i5 = mul i32 %3, %4
  store i32 %i5, i32* %i
  %5 = load <4 x float>* %v
  %6 = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %5)
  %7 = load <4 x float>* %v
  %v6 = fadd <4 x float> %7, %6
  store <4 x float> %v6, <4 x float>* %v
  %8 = load <4 x float>* %v
  %v7 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %8)
  %9 = load <4 x float>* %v
  %v8 = fadd <4 x float> %9, %v7
  store <4 x float> %v8, <4 x float>* %v
  %10 = load <4 x float>* %v
  %v9 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %10)
  %11 = load <4 x float>* %v
  %v10 = fadd <4 x float> %11, %v9
  store <4 x float> %v10, <4 x float>* %v
  %12 = load <4 x float>* %v
  %v11 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %12)
  %13 = load <4 x float>* %v
  %v12 = fadd <4 x float> %13, %v11
  store <4 x float> %v12, <4 x float>* %v
  %14 = load <4 x float>* %v
  %v13 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %14)
  %15 = load <4 x float>* %v
  %v14 = fadd <4 x float> %15, %v13
  store <4 x float> %v14, <4 x float>* %v
  %16 = load <4 x float>* %v
  %v15 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %16)
  %17 = load <4 x float>* %v
  %v16 = fadd <4 x float> %17, %v15
  store <4 x float> %v16, <4 x float>* %v
  %18 = load <4 x float>* %v
  %v17 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %18)
  %19 = load <4 x float>* %v
  %v18 = fadd <4 x float> %19, %v17
  store <4 x float> %v18, <4 x float>* %v
  %20 = load <4 x float>* %v
  %v19 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %20)
  %21 = load <4 x float>* %v
  %v20 = fadd <4 x float> %21, %v19
  store <4 x float> %v20, <4 x float>* %v
  %22 = load <4 x float>* %v
  %v21 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %22)
  %23 = load <4 x float>* %v
  %v22 = fadd <4 x float> %23, %v21
  store <4 x float> %v22, <4 x float>* %v
  %24 = load <4 x float>* %v
  %v23 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %24)
  %25 = load <4 x float>* %v
  %v24 = fadd <4 x float> %25, %v23
  store <4 x float> %v24, <4 x float>* %v
  %26 = load <4 x float>* %v
  %v25 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %26)
  %27 = load <4 x float>* %v
  %v26 = fadd <4 x float> %27, %v25
  store <4 x float> %v26, <4 x float>* %v
  %28 = load <4 x float>* %v
  %v27 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %28)
  %29 = load <4 x float>* %v
  %v28 = fadd <4 x float> %29, %v27
  store <4 x float> %v28, <4 x float>* %v
  %30 = load <4 x float>* %v
  %31 = load <4 x float>* %v
  %v29 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %30, <4 x float> %31)
  %32 = load <4 x float>* %v
  %v30 = fadd <4 x float> %32, %v29
  store <4 x float> %v30, <4 x float>* %v
  %33 = load <4 x float>* %v
  %v31 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %33)
  %34 = load <4 x float>* %v
  %v32 = fadd <4 x float> %34, %v31
  store <4 x float> %v32, <4 x float>* %v
  %35 = load <4 x float>* %v
  %v33 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %35)
  %36 = load <4 x float>* %v
  %v34 = fadd <4 x float> %36, %v33
  store <4 x float> %v34, <4 x float>* %v
  %37 = load <4 x float>* %v
  %v35 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %37)
  %38 = load <4 x float>* %v
  %v36 = fadd <4 x float> %38, %v35
  store <4 x float> %v36, <4 x float>* %v
  %39 = load <4 x float>* %v
  %v37 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %39)
  %40 = load <4 x float>* %v
  %v38 = fadd <4 x float> %40, %v37
  store <4 x float> %v38, <4 x float>* %v
  %41 = load <4 x float>* %v
  %v39 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %41)
  %42 = load <4 x float>* %v
  %v40 = fadd <4 x float> %42, %v39
  store <4 x float> %v40, <4 x float>* %v
  %43 = load <4 x float>* %v
  %v41 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %43)
  %44 = load <4 x float>* %v
  %v42 = fadd <4 x float> %44, %v41
  store <4 x float> %v42, <4 x float>* %v
  %45 = load <4 x float>* %v
  %v43 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %45)
  %46 = load <4 x float>* %v
  %v44 = fadd <4 x float> %46, %v43
  store <4 x float> %v44, <4 x float>* %v
  %47 = load <4 x float>* %v
  %v45 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %47)
  %48 = load <4 x float>* %v
  %v46 = fadd <4 x float> %48, %v45
  store <4 x float> %v46, <4 x float>* %v
  %49 = load <4 x float>* %v
  %v47 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %49)
  %50 = load <4 x float>* %v
  %v48 = fadd <4 x float> %50, %v47
  store <4 x float> %v48, <4 x float>* %v
  %51 = load <4 x float>* %v
  %v49 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %51)
  %52 = load <4 x float>* %v
  %v50 = fadd <4 x float> %52, %v49
  store <4 x float> %v50, <4 x float>* %v
  %53 = load <4 x float>* %v
  %v51 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %53)
  %54 = load <4 x float>* %v
  %v52 = fadd <4 x float> %54, %v51
  store <4 x float> %v52, <4 x float>* %v
  %55 = load <4 x float>* %v
  %56 = load <4 x float>* %v
  %57 = frem <4 x float> %55, %56
  %58 = load <4 x float>* %v
  %v53 = fadd <4 x float> %58, %57
  store <4 x float> %v53, <4 x float>* %v
  %59 = load <4 x float>* %v
  %60 = load <4 x float>* %v
  %61 = extractelement <4 x float> %60, i32 0
  %62 = insertelement <4 x float> undef, float %61, i32 0
  %63 = insertelement <4 x float> %62, float %61, i32 1
  %64 = insertelement <4 x float> %63, float %61, i32 2
  %65 = insertelement <4 x float> %64, float %61, i32 3
  %66 = frem <4 x float> %59, %65
  %67 = load <4 x float>* %v
  %v54 = fadd <4 x float> %67, %66
  store <4 x float> %v54, <4 x float>* %v
  %68 = load <4 x float>* %v
  %69 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v55 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %68, <4 x float> %69)
  %70 = load <4 x float>* %v
  %v56 = fadd <4 x float> %70, %v55
  store <4 x float> %v56, <4 x float>* %v
  %71 = load <4 x float>* %v
  %72 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v57 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %71, <4 x float> %72)
  %73 = load <4 x float>* %v
  %v58 = fadd <4 x float> %73, %v57
  store <4 x float> %v58, <4 x float>* %v
  %74 = load <4 x float>* %v
  %75 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %76 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v59 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %74, <4 x float> %75, <4 x float> %76)
  %77 = load <4 x float>* %v
  %v60 = fadd <4 x float> %77, %v59
  store <4 x float> %v60, <4 x float>* %v
  %78 = load <4 x float>* %v
  %79 = load <4 x float>* %v
  %80 = load <4 x float>* %v
  %v61 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %78, <4 x float> %79, <4 x float> %80)
  %81 = load <4 x float>* %v
  %v62 = fadd <4 x float> %81, %v61
  store <4 x float> %v62, <4 x float>* %v
  %82 = load <4 x float>* %v
  %83 = load <4 x float>* %v
  %v63 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %82, <4 x float> %83)
  %84 = load <4 x float>* %v
  %v64 = fadd <4 x float> %84, %v63
  store <4 x float> %v64, <4 x float>* %v
  %85 = load <4 x float>* %v
  %86 = load <4 x float>* %v
  %87 = load <4 x float>* %v
  %v65 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %85, <4 x float> %86, <4 x float> %87)
  %88 = load <4 x float>* %v
  %v66 = fadd <4 x float> %88, %v65
  store <4 x float> %v66, <4 x float>* %v
  %89 = load float addrspace(2)* @uf, !gla.uniform !4
  %90 = load <4 x float>* %v
  %v67 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %89, <4 x float> %90)
  %91 = load <4 x float>* %v
  %v68 = fadd <4 x float> %91, %v67
  store <4 x float> %v68, <4 x float>* %v
  %92 = load float addrspace(2)* @uf, !gla.uniform !4
  %93 = load float addrspace(2)* @uf, !gla.uniform !4
  %94 = load <4 x float>* %v
  %v69 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %92, float %93, <4 x float> %94)
  %95 = load <4 x float>* %v
  %v70 = fadd <4 x float> %95, %v69
  store <4 x float> %v70, <4 x float>* %v
  %96 = load <4 x float>* %v
  %v71 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %96)
  %97 = load <4 x float>* %v
  %v72 = fadd <4 x float> %97, %v71
  store <4 x float> %v72, <4 x float>* %v
  %98 = load <4 x float>* %v
  %99 = load <4 x float>* %v
  %100 = load <4 x float>* %v
  %v73 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %98, <4 x float> %99, <4 x float> %100)
  %101 = load <4 x float>* %v
  %v74 = fadd <4 x float> %101, %v73
  store <4 x float> %v74, <4 x float>* %v
  %102 = load <4 x float>* %v
  %103 = load <4 x float>* %v
  %v75 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %102, <4 x float> %103)
  %104 = load <4 x float>* %v
  %v76 = fadd <4 x float> %104, %v75
  store <4 x float> %v76, <4 x float>* %v
  %105 = load <4 x float>* %v
  %106 = load <4 x float>* %v
  %107 = load float addrspace(2)* @uf, !gla.uniform !4
  %v77 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %105, <4 x float> %106, float %107)
  %108 = load <4 x float>* %v
  %v78 = fadd <4 x float> %108, %v77
  store <4 x float> %v78, <4 x float>* %v
  %109 = load <4 x float>* %v
  %v79 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %109)
  %110 = load <4 x float>* %v
  %v80 = fadd <4 x float> %110, %v79
  store <4 x float> %v80, <4 x float>* %v
  %111 = load <4 x float>* %v
  %v81 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %111)
  %112 = load <4 x float>* %v
  %v82 = fadd <4 x float> %112, %v81
  store <4 x float> %v82, <4 x float>* %v
  %113 = load <4 x float>* %v
  %v83 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %113)
  %114 = load <4 x float>* %v
  %v84 = fadd <4 x float> %114, %v83
  store <4 x float> %v84, <4 x float>* %v
  %115 = load <4 x float>* %v
  %116 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %117 = fcmp olt <4 x float> %115, %116
  %b86 = call i1 @llvm.gla.any.v4i1(<4 x i1> %117)
  store i1 %b86, i1* %b
  %118 = load i1* %b
  %119 = load <4 x float>* %v
  %120 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %121 = fcmp ole <4 x float> %119, %120
  %b87 = call i1 @llvm.gla.any.v4i1(<4 x i1> %121)
  %b88 = and i1 %118, %b87
  store i1 %b88, i1* %b
  %122 = load i1* %b
  %123 = load <4 x float>* %v
  %124 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %125 = fcmp ogt <4 x float> %123, %124
  %b89 = call i1 @llvm.gla.any.v4i1(<4 x i1> %125)
  %b90 = and i1 %122, %b89
  store i1 %b90, i1* %b
  %126 = load i1* %b
  %127 = load <4 x float>* %v
  %128 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %129 = fcmp oge <4 x float> %127, %128
  %b91 = call i1 @llvm.gla.any.v4i1(<4 x i1> %129)
  %b92 = and i1 %126, %b91
  store i1 %b92, i1* %b
  %130 = load i1* %b
  %131 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %132 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %133 = icmp eq <4 x i1> %131, %132
  %b93 = call i1 @llvm.gla.any.v4i1(<4 x i1> %133)
  %b94 = and i1 %130, %b93
  store i1 %b94, i1* %b
  %134 = load i1* %b
  %135 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %136 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %137 = icmp ne <4 x i1> %135, %136
  %b95 = call i1 @llvm.gla.any.v4i1(<4 x i1> %137)
  %b96 = and i1 %134, %b95
  store i1 %b96, i1* %b
  %138 = load i1* %b
  %139 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %b97 = call i1 @llvm.gla.any.v4i1(<4 x i1> %139)
  %b98 = and i1 %138, %b97
  store i1 %b98, i1* %b
  %140 = load i1* %b
  %141 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %b99 = call i1 @llvm.gla.all.v4i1(<4 x i1> %141)
  %b100 = and i1 %140, %b99
  store i1 %b100, i1* %b
  %142 = load i1* %b
  %143 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %144 = xor <4 x i1> %143, <i1 true, i1 true, i1 true, i1 true>
  %b101 = call i1 @llvm.gla.any.v4i1(<4 x i1> %144)
  %b102 = and i1 %142, %b101
  store i1 %b102, i1* %b
  %145 = load i32* %i
  %146 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %147 = add i32 %145, %146
  %148 = load i32* %i
  %149 = mul i32 %147, %148
  %150 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %151 = sub i32 %149, %150
  %152 = load i32* %i
  %i103 = sdiv i32 %151, %152
  store i32 %i103, i32* %i
  %153 = load i32* %i
  %154 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i104 = srem i32 %153, %154
  store i32 %i104, i32* %i
  %155 = load i32* %i
  %156 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %157 = icmp eq i32 %155, %156
  %158 = load i32* %i
  %159 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %160 = icmp ne i32 %158, %159
  %161 = load i32* %i
  %162 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %163 = icmp eq i32 %161, %162
  %164 = and i1 %160, %163
  %165 = load i32* %i
  %166 = icmp ne i32 %165, 2
  %167 = xor i1 %164, %166
  %168 = or i1 %157, %167
  br i1 %168, label %then, label %ifmerge

then:                                             ; preds = %entry
  %169 = load i32* %i
  %i105 = add i32 %169, 1
  store i32 %i105, i32* %i
  br label %ifmerge

ifmerge:                                          ; preds = %entry, %then
  %170 = load float addrspace(2)* @uf, !gla.uniform !4
  %171 = load float addrspace(2)* @uf, !gla.uniform !4
  %172 = fadd float %170, %171
  %173 = load float addrspace(2)* @uf, !gla.uniform !4
  %174 = fmul float %172, %173
  %175 = load float addrspace(2)* @uf, !gla.uniform !4
  %176 = fsub float %174, %175
  %177 = load float addrspace(2)* @uf, !gla.uniform !4
  %f106 = fdiv float %176, %177
  store float %f106, float* %f
  %178 = load <4 x float>* %v
  %f107 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %178)
  %179 = load float* %f
  %f108 = fadd float %179, %f107
  store float %f108, float* %f
  %180 = load <4 x float>* %v
  %181 = load <4 x float>* %v
  %f109 = call float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float> %180, <4 x float> %181)
  %182 = load float* %f
  %f110 = fadd float %182, %f109
  store float %f110, float* %f
  %183 = load <4 x float>* %v
  %184 = load <4 x float>* %v
  %f111 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %183, <4 x float> %184)
  %185 = load float* %f
  %f112 = fadd float %185, %f111
  store float %f112, float* %f
  %186 = load float* %f
  %187 = load float addrspace(2)* @uf, !gla.uniform !4
  %188 = fmul float %186, %187
  %189 = load float* %f
  %f113 = fadd float %189, %188
  store float %f113, float* %f
  %190 = load <4 x float>* %v
  %191 = extractelement <4 x float> %190, i32 0
  %192 = insertelement <3 x float> undef, float %191, i32 0
  %193 = extractelement <4 x float> %190, i32 1
  %194 = insertelement <3 x float> %192, float %193, i32 1
  %195 = extractelement <4 x float> %190, i32 2
  %196 = insertelement <3 x float> %194, float %195, i32 2
  %197 = load <4 x float>* %v
  %198 = extractelement <4 x float> %197, i32 0
  %199 = insertelement <3 x float> undef, float %198, i32 0
  %200 = extractelement <4 x float> %197, i32 1
  %201 = insertelement <3 x float> %199, float %200, i32 1
  %202 = extractelement <4 x float> %197, i32 2
  %203 = insertelement <3 x float> %201, float %202, i32 2
  %f114 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %196, <3 x float> %203)
  %204 = extractelement <3 x float> %f114, i32 0
  %205 = load float* %f
  %f115 = fadd float %205, %204
  store float %f115, float* %f
  %206 = load float* %f
  %207 = load float addrspace(2)* @uf, !gla.uniform !4
  %208 = fcmp oeq float %206, %207
  %209 = load float* %f
  %210 = load float addrspace(2)* @uf, !gla.uniform !4
  %211 = fcmp one float %209, %210
  %212 = load float* %f
  %213 = fcmp one float %212, 2.000000e+00
  %214 = and i1 %211, %213
  %215 = or i1 %208, %214
  br i1 %215, label %then116, label %ifmerge118

then116:                                          ; preds = %ifmerge
  %216 = load float* %f
  %f117 = fadd float %216, 1.000000e+00
  store float %f117, float* %f
  br label %ifmerge118

ifmerge118:                                       ; preds = %ifmerge, %then116
  %217 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %218 = load i32* %i
  %i119 = and i32 %218, %217
  store i32 %i119, i32* %i
  %219 = load i32* %i
  %i120 = or i32 %219, 66
  store i32 %i120, i32* %i
  %220 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %221 = load i32* %i
  %i121 = xor i32 %221, %220
  store i32 %i121, i32* %i
  %222 = load i32* %i
  %i122 = srem i32 %222, 17
  store i32 %i122, i32* %i
  %223 = load i32* %i
  %i123 = ashr i32 %223, 2
  store i32 %i123, i32* %i
  %224 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %225 = load i32* %i
  %i124 = shl i32 %225, %224
  store i32 %i124, i32* %i
  %226 = load i32* %i
  %i125 = xor i32 %226, -1
  store i32 %i125, i32* %i
  %227 = load i1* %b
  %b126 = xor i1 %227, true
  store i1 %b126, i1* %b
  %228 = load i1* %b
  br i1 %228, label %then127, label %else

then127:                                          ; preds = %ifmerge118
  %229 = load i32* %i
  %230 = sitofp i32 %229 to float
  %231 = load <4 x float>* %gl_FragColor128
  %232 = insertelement <4 x float> undef, float %230, i32 0
  %233 = insertelement <4 x float> %232, float %230, i32 1
  %234 = insertelement <4 x float> %233, float %230, i32 2
  %235 = insertelement <4 x float> %234, float %230, i32 3
  %236 = load float* %f
  %237 = load <4 x float>* %gl_FragColor129
  %238 = insertelement <4 x float> undef, float %236, i32 0
  %239 = insertelement <4 x float> %238, float %236, i32 1
  %240 = insertelement <4 x float> %239, float %236, i32 2
  %241 = insertelement <4 x float> %240, float %236, i32 3
  %242 = fadd <4 x float> %235, %241
  %243 = load <4 x float>* %v
  %gl_FragColor130 = fadd <4 x float> %242, %243
  store <4 x float> %gl_FragColor130, <4 x float>* %gl_FragColor
  br label %ifmerge132

else:                                             ; preds = %ifmerge118
  %gl_FragColor131 = load <4 x float>* %v
  store <4 x float> %gl_FragColor131, <4 x float>* %gl_FragColor
  br label %ifmerge132

ifmerge132:                                       ; preds = %else, %then127
  %gl_FragColor133 = load <4 x float>* %gl_FragColor
  store <4 x float> %gl_FragColor133, <4 x float>* @gl_FragColor
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %ifmerge132
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}


Bottom IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer

define fastcc void @main() {
entry:
  %0 = load <4 x float> addrspace(2)* @uv4, align 16, !gla.uniform !1
  %1 = fmul <4 x float> %0, <float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000>
  %2 = fmul <4 x float> %1, <float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000>
  %v4 = fadd <4 x float> %1, %2
  %3 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i5 = mul i32 %3, %3
  %4 = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %v4)
  %v6 = fadd <4 x float> %4, %v4
  %v7 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %v6)
  %v8 = fadd <4 x float> %v7, %v6
  %v9 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %v8)
  %v10 = fadd <4 x float> %v9, %v8
  %v11 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %v10)
  %v12 = fadd <4 x float> %v11, %v10
  %v13 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %v12)
  %v14 = fadd <4 x float> %v13, %v12
  %v15 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %v14)
  %v16 = fadd <4 x float> %v15, %v14
  %v17 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %v16)
  %v18 = fadd <4 x float> %v17, %v16
  %v19 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %v18)
  %v20 = fadd <4 x float> %v19, %v18
  %v21 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %v20)
  %v22 = fadd <4 x float> %v21, %v20
  %v23 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %v22)
  %v24 = fadd <4 x float> %v23, %v22
  %v25 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %v24)
  %v26 = fadd <4 x float> %v25, %v24
  %v27 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %v26)
  %v28 = fadd <4 x float> %v27, %v26
  %v29 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %v28, <4 x float> %v28)
  %v30 = fadd <4 x float> %v29, %v28
  %v31 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %v30)
  %v32 = fadd <4 x float> %v31, %v30
  %v33 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %v32)
  %v34 = fadd <4 x float> %v33, %v32
  %v35 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %v34)
  %v36 = fadd <4 x float> %v35, %v34
  %v37 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %v36)
  %v38 = fadd <4 x float> %v37, %v36
  %v39 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %v38)
  %v40 = fadd <4 x float> %v39, %v38
  %v41 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %v40)
  %v42 = fadd <4 x float> %v41, %v40
  %v43 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %v42)
  %v44 = fadd <4 x float> %v43, %v42
  %v45 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %v44)
  %v46 = fadd <4 x float> %v45, %v44
  %v47 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %v46)
  %v48 = fadd <4 x float> %v47, %v46
  %v49 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %v48)
  %v50 = fadd <4 x float> %v49, %v48
  %v51 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %v50)
  %v52 = fadd <4 x float> %v51, %v50
  %5 = frem <4 x float> %v52, %v52
  %v53 = fadd <4 x float> %5, %v52
  %6 = call <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float> %v53, <4 x i32> zeroinitializer)
  %7 = frem <4 x float> %v53, %6
  %v54 = fadd <4 x float> %7, %v53
  %v55 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %v54, <4 x float> %0)
  %v56 = fadd <4 x float> %v55, %v54
  %v57 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %v56, <4 x float> %0)
  %v58 = fadd <4 x float> %v57, %v56
  %v59 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %v58, <4 x float> %0, <4 x float> %0)
  %v60 = fadd <4 x float> %v59, %v58
  %v61 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %v60, <4 x float> %v60, <4 x float> %v60)
  %v62 = fadd <4 x float> %v61, %v60
  %v63 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %v62, <4 x float> %v62)
  %v64 = fadd <4 x float> %v63, %v62
  %v65 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %v64, <4 x float> %v64, <4 x float> %v64)
  %v66 = fadd <4 x float> %v65, %v64
  %8 = load float addrspace(2)* @uf, align 4, !gla.uniform !4
  %v67 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %8, <4 x float> %v66)
  %v68 = fadd <4 x float> %v66, %v67
  %v69 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %8, float %8, <4 x float> %v68)
  %v70 = fadd <4 x float> %v68, %v69
  %v71 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %v70)
  %v72 = fadd <4 x float> %v70, %v71
  %v73 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %v72, <4 x float> %v72, <4 x float> %v72)
  %v74 = fadd <4 x float> %v72, %v73
  %v75 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %v74, <4 x float> %v74)
  %v76 = fadd <4 x float> %v74, %v75
  %v77 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %v76, <4 x float> %v76, float %8)
  %v78 = fadd <4 x float> %v76, %v77
  %v79 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %v78)
  %v80 = fadd <4 x float> %v78, %v79
  %v81 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %v80)
  %v82 = fadd <4 x float> %v80, %v81
  %v83 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %v82)
  %v84 = fadd <4 x float> %v82, %v83
  %9 = call <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float> %v84, <3 x i32> <i32 0, i32 1, i32 2>)
  %10 = fcmp olt <4 x float> %v84, %0
  %b86 = call i1 @llvm.gla.any.v4i1(<4 x i1> %10)
  %11 = fcmp ole <4 x float> %v84, %0
  %b87 = call i1 @llvm.gla.any.v4i1(<4 x i1> %11)
  %b88 = and i1 %b86, %b87
  %12 = fcmp ogt <4 x float> %v84, %0
  %b89 = call i1 @llvm.gla.any.v4i1(<4 x i1> %12)
  %b90 = and i1 %b88, %b89
  %13 = fcmp oge <4 x float> %v84, %0
  %b91 = call i1 @llvm.gla.any.v4i1(<4 x i1> %13)
  %b92 = and i1 %b90, %b91
  %14 = load <4 x i1> addrspace(2)* @ub41, align 4, !gla.uniform !5
  %15 = load <4 x i1> addrspace(2)* @ub42, align 4, !gla.uniform !6
  %16 = icmp eq <4 x i1> %14, %15
  %b93 = call i1 @llvm.gla.any.v4i1(<4 x i1> %16)
  %b94 = and i1 %b92, %b93
  %17 = icmp ne <4 x i1> %14, %15
  %b95 = call i1 @llvm.gla.any.v4i1(<4 x i1> %17)
  %b96 = and i1 %b94, %b95
  %b97 = call i1 @llvm.gla.any.v4i1(<4 x i1> %14)
  %b98 = and i1 %b96, %b97
  %b99 = call i1 @llvm.gla.all.v4i1(<4 x i1> %14)
  %b100 = and i1 %b98, %b99
  %18 = xor <4 x i1> %14, <i1 true, i1 true, i1 true, i1 true>
  %b101 = call i1 @llvm.gla.any.v4i1(<4 x i1> %18)
  %b102 = and i1 %b100, %b101
  %19 = add i32 %i5, %3
  %20 = mul i32 %19, %i5
  %21 = sub i32 %20, %3
  %i103 = sdiv i32 %21, %i5
  %i104 = srem i32 %i103, %3
  %22 = icmp eq i32 %i104, 2
  %i105 = add i32 %i104, 1
  %.i105 = select i1 %22, i32 0, i32 %i105
  %23 = fadd float %8, %8
  %24 = fmul float %8, %23
  %25 = fsub float %24, %8
  %f106 = fdiv float %25, %8
  %f107 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %v84)
  %f108 = fadd float %f106, %f107
  %f111 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %v84, <4 x float> %v84)
  %f112 = fadd float %f108, %f111
  %26 = fmul float %8, %f112
  %f113 = fadd float %f112, %26
  %f114 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %9, <3 x float> %9)
  %27 = extractelement <3 x float> %f114, i32 0
  %f115 = fadd float %27, %f113
  %28 = fcmp oeq float %f115, %8
  %29 = fcmp one float %f115, %8
  %30 = fcmp one float %f115, 2.000000e+00
  %31 = and i1 %29, %30
  %32 = or i1 %28, %31
  %f117 = fadd float %f115, 1.000000e+00
  %select134 = select i1 %32, float %f117, float %f115
  %33 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %select134, <4 x i32> zeroinitializer)
  %34 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i119 = and i32 %34, %.i105
  %i120 = or i32 %i119, 66
  %i121 = xor i32 %i120, %34
  %i122 = srem i32 %i121, 17
  %i123 = ashr i32 %i122, 2
  %i124 = shl i32 %i123, %34
  %i125 = xor i32 %i124, -1
  %35 = sitofp i32 %i125 to float
  %36 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %35, <4 x i32> zeroinitializer)
  %37 = fadd <4 x float> %36, %33
  %gl_FragColor130 = fadd <4 x float> %v84, %37
  %select = select i1 %b102, <4 x float> %v84, <4 x float> %gl_FragColor130
  store <4 x float> %select, <4 x float>* @gl_FragColor, align 16
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %entry
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float>, <4 x i32>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float>, <3 x i32>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float, <4 x i32>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}
#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 C_vssely1 = vec4(0.0174533);
const vec4 C_4bmlfm = vec4(57.2958);
const int C_2 = 2;
const int C_1 = 1;
const int C_0 = 0;
const float C_2d0 = 2.0;
const float C_1d0 = 1.0;
const int C_66 = 66;
const int C_17 = 17;

void main()
{
	vec4 H_hgy73b1 = uv4 * C_vssely1;
	vec4 H_rrtr9n = H_hgy73b1 * C_4bmlfm;
	vec4 H_2u0bi2 = H_hgy73b1 + H_rrtr9n;
	int H_h8ktht1 = ui * ui;
	vec4 H_pr406p1 = sin(H_2u0bi2);
	vec4 H_1sil091 = H_2u0bi2 + H_pr406p1;
	vec4 H_pm9wt4 = cos(H_1sil091);
	vec4 H_60zb061 = H_1sil091 + H_pm9wt4;
	vec4 H_vqt3cx1 = tan(H_60zb061);
	vec4 H_b8e3h6 = H_60zb061 + H_vqt3cx1;
	vec4 H_mmsxys = asin(H_b8e3h6);
	vec4 H_fyum081 = H_b8e3h6 + H_mmsxys;
	vec4 H_xttkch = acos(H_fyum081);
	vec4 H_27h57a = H_fyum081 + H_xttkch;
	vec4 H_nzxhnp1 = atan(H_27h57a);
	vec4 H_jrwraf = H_27h57a + H_nzxhnp1;
	vec4 H_9ccpbm = sinh(H_jrwraf);
	vec4 H_iukhwg = H_9ccpbm + H_jrwraf;
	vec4 H_t95rkq1 = cosh(H_iukhwg);
	vec4 H_26o6hf = H_iukhwg + H_t95rkq1;
	vec4 H_9d78cj = tanh(H_26o6hf);
	vec4 H_49fyhm1 = H_26o6hf + H_9d78cj;
	vec4 H_sricuv1 = asinh(H_49fyhm1);
	vec4 H_bfg9ms1 = H_49fyhm1 + H_sricuv1;
	vec4 H_onqi3g1 = acosh(H_bfg9ms1);
	vec4 H_5yaqxs1 = H_bfg9ms1 + H_onqi3g1;
	vec4 H_lkv4ho1 = atanh(H_5yaqxs1);
	vec4 H_f8j5vq = H_5yaqxs1 + H_lkv4ho1;
	vec4 H_2mywoc = pow(H_f8j5vq, H_f8j5vq);
	vec4 H_tgc07q = H_2mywoc + H_f8j5vq;
	vec4 H_qpu2a11 = exp(H_tgc07q);
	vec4 H_dk4dcj = H_qpu2a11 + H_tgc07q;
	vec4 H_9xbaf = log(H_dk4dcj);
	vec4 H_svrpa71 = H_9xbaf + H_dk4dcj;
	vec4 H_ac2bc21 = exp2(H_svrpa71);
	vec4 H_katd4g1 = H_ac2bc21 + H_svrpa71;
	vec4 H_dsrnja = log2(H_katd4g1);
	vec4 H_2xmg6e = H_dsrnja + H_katd4g1;
	vec4 H_qojjv81 = sqrt(H_2xmg6e);
	vec4 H_823mgg = H_2xmg6e + H_qojjv81;
	vec4 H_lhpqhc1 = inversesqrt(H_823mgg);
	vec4 H_vu6cwi = H_823mgg + H_lhpqhc1;
	vec4 H_hybov3 = abs(H_vu6cwi);
	vec4 H_ls6j7z = H_hybov3 + H_vu6cwi;
	vec4 H_497jwu = sign(H_ls6j7z);
	vec4 H_8q4sa4 = H_497jwu + H_ls6j7z;
	vec4 H_4r9tqn1 = floor(H_8q4sa4);
	vec4 H_cq21og = H_4r9tqn1 + H_8q4sa4;
	vec4 H_pnd8en1 = ceil(H_cq21og);
	vec4 H_5ihndv1 = H_cq21og + H_pnd8en1;
	vec4 H_0fqsuy1 = fract(H_5ihndv1);
	vec4 H_0fwhsb1 = H_0fqsuy1 + H_5ihndv1;
	vec4 H_chemma = mod(H_0fwhsb1, H_0fwhsb1);
	vec4 H_4b0dru1 = H_0fwhsb1 + H_chemma;
	vec4 H_6twtmm = mod(H_4b0dru1, H_4b0dru1.xxxx);
	vec4 H_fc6qim = H_4b0dru1 + H_6twtmm;
	vec4 H_4ynrbx1 = min(H_fc6qim, uv4);
	vec4 H_qme0uc1 = H_4ynrbx1 + H_fc6qim;
	vec4 H_4mh53o1 = max(H_qme0uc1, uv4);
	vec4 H_d1n5jt = H_4mh53o1 + H_qme0uc1;
	vec4 H_2g9xs11 = clamp(H_d1n5jt, uv4, uv4);
	vec4 H_hnouuf = H_2g9xs11 + H_d1n5jt;
	vec4 H_iz8nxl = mix(H_hnouuf, H_hnouuf, H_hnouuf);
	vec4 H_o2jgoh = H_hnouuf + H_iz8nxl;
	vec4 H_gaxasp = step(H_o2jgoh, H_o2jgoh);
	vec4 H_3ou1m8 = H_gaxasp + H_o2jgoh;
	vec4 H_67nxre1 = smoothstep(H_3ou1m8, H_3ou1m8, H_3ou1m8);
	vec4 H_0t4vln1 = H_3ou1m8 + H_67nxre1;
	vec4 H_1vz1wq = step(uf, H_0t4vln1);
	vec4 H_xcgc5f1 = H_0t4vln1 + H_1vz1wq;
	vec4 H_o7jeak1 = smoothstep(uf, uf, H_xcgc5f1);
	vec4 H_b9n64q = H_o7jeak1 + H_xcgc5f1;
	vec4 H_q3slgi = normalize(H_b9n64q);
	vec4 H_3jo1tj1 = H_b9n64q + H_q3slgi;
	vec4 H_lrjeix1 = faceforward(H_3jo1tj1, H_3jo1tj1, H_3jo1tj1);
	vec4 H_tankrk = H_3jo1tj1 + H_lrjeix1;
	vec4 H_x6ffun1 = reflect(H_tankrk, H_tankrk);
	vec4 H_lwyi2i1 = H_tankrk + H_x6ffun1;
	vec4 H_uubbzb = refract(H_lwyi2i1, H_lwyi2i1, uf);
	vec4 H_bwor98 = H_lwyi2i1 + H_uubbzb;
	vec4 H_2802gi1 = dFdx(H_bwor98);
	vec4 H_cbjb581 = H_2802gi1 + H_bwor98;
	vec4 H_36po411 = dFdy(H_cbjb581);
	vec4 H_bn7jta = H_36po411 + H_cbjb581;
	vec4 H_tzraew = fwidth(H_bn7jta);
	vec4 H_fzc38q1 = H_bn7jta + H_tzraew;
	bvec4 H_gnurdt = lessThan(H_fzc38q1, uv4);
	bool H_jzivur1 = any(H_gnurdt);
	bvec4 H_qykp4o = lessThanEqual(H_fzc38q1, uv4);
	bool H_lxg04n1 = any(H_qykp4o);
	bool H_e65ujj1 = H_jzivur1 && H_lxg04n1;
	bvec4 H_po3x9e1 = greaterThan(H_fzc38q1, uv4);
	bool H_smlg6k = any(H_po3x9e1);
	bool H_72o0hj1 = H_e65ujj1 && H_smlg6k;
	bvec4 H_h7acak1 = greaterThanEqual(H_fzc38q1, uv4);
	bool H_xmtkou1 = any(H_h7acak1);
	bool H_rio2t = H_72o0hj1 && H_xmtkou1;
	bvec4 H_vlocan1 = equal(ub41, ub42);
	bool H_by51mk1 = any(H_vlocan1);
	bool H_dpz2rs = H_rio2t && H_by51mk1;
	bvec4 H_e6ku4t1 = notEqual(ub41, ub42);
	bool H_rjqzlx = any(H_e6ku4t1);
	bool H_1f85631 = H_dpz2rs && H_rjqzlx;
	bool H_u0wve91 = any(ub41);
	bool H_8lgm1k = H_1f85631 && H_u0wve91;
	bool H_f4b5uh1 = all(ub41);
	bool H_2t4w5q = H_8lgm1k && H_f4b5uh1;
	bvec4 H_db60wu = not(ub41);
	bool H_hpec3a1 = any(H_db60wu);
	bool H_3ewbjk = H_2t4w5q && H_hpec3a1;
	int H_ngz3vc1 = H_h8ktht1 + ui;
	int H_l1vuw31 = H_h8ktht1 * H_ngz3vc1;
	int H_2knscd = H_l1vuw31 - ui;
	int H_rq4ows = H_2knscd / H_h8ktht1;
	int H_xtc1vg = H_rq4ows % ui;
	bool H_ry3ksp = H_xtc1vg == C_2;
	int H_3j3nrk1 = H_xtc1vg + C_1;
	int _L = H_ry3ksp ? C_0 : H_3j3nrk1;
	float H_6ra9oe1 = uf + uf;
	float H_eccx591 = H_6ra9oe1 * uf;
	float H_my73qz = H_eccx591 - uf;
	float H_1umaut = H_my73qz / uf;
	float H_pebi7n1 = length(H_fzc38q1);
	float H_5868mb1 = H_1umaut + H_pebi7n1;
	float H_9xgw8z = dot(H_fzc38q1, H_fzc38q1);
	float H_ahac5a1 = H_5868mb1 + H_9xgw8z;
	float H_7kv9h31 = H_ahac5a1 * uf;
	float H_xz4r07 = H_7kv9h31 + H_ahac5a1;
	vec3 H_ku1yjn1 = cross(H_fzc38q1.xyz, H_fzc38q1.xyz);
	float H_yu4764 = H_ku1yjn1.x + H_xz4r07;
	bool H_kot1tw1 = H_yu4764 == uf;
	bool H_kzsh59 = H_yu4764 != uf;
	bool H_ppnz8y = H_yu4764 != C_2d0;
	bool H_qnzi2l = H_kzsh59 && H_ppnz8y;
	bool H_247rn71 = H_kot1tw1 || H_qnzi2l;
	float H_94a7zi1 = H_yu4764 + C_1d0;
	float select = H_247rn71 ? H_94a7zi1 : H_yu4764;
	vec4 H_c1z5nn = vec4(select);
	int H_sigq8q1 = ui & _L;
	int H_s9dupe1 = H_sigq8q1 | C_66;
	int H_dz351k1 = H_s9dupe1 ^ ui;
	int H_8w7dri1 = H_dz351k1 % C_17;
	int H_qlaxc41 = H_8w7dri1 >> C_2;
	int H_sf9rny = H_qlaxc41 << ui;
	int H_8iiwvi1 = ~(H_sf9rny);
	float H_yrfrlx1 = float(H_8iiwvi1);
	vec4 H_x2iwni1 = vec4(H_yrfrlx1);
	vec4 H_hfe3lx = H_c1z5nn + H_x2iwni1;
	vec4 Ll_FragColor1 = H_fzc38q1 + H_hfe3lx;
	vec4 select1 = H_3ewbjk ? H_fzc38q1 : Ll_FragColor1;
	gl_FragColor = select1;
	
}

#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 C_vssely1 = vec4(0.0174533);
const vec4 C_4bmlfm = vec4(57.2958);
const int C_2 = 2;
const int C_1 = 1;
const int C_0 = 0;
const float C_2d0 = 2.0;
const float C_1d0 = 1.0;
const int C_66 = 66;
const int C_17 = 17;

void main()
{
	vec4 H_hgy73b = uv4 * C_vssely1;
	vec4 H_rrtr9n = H_hgy73b * C_4bmlfm;
	vec4 H_2u0bi = H_hgy73b + H_rrtr9n;
	int H_h8ktht = ui * ui;
	vec4 H_pr406p = sin(H_2u0bi);
	vec4 H_1sil = H_2u0bi + H_pr406p;
	vec4 H_pm9wt = cos(H_1sil);
	vec4 H_60zb = H_1sil + H_pm9wt;
	vec4 H_vqt3cx = tan(H_60zb);
	vec4 H_b8e3h = H_60zb + H_vqt3cx;
	vec4 H_mmsxys = asin(H_b8e3h);
	vec4 H_fyum = H_b8e3h + H_mmsxys;
	vec4 H_xttkch = acos(H_fyum);
	vec4 H_27h57a = H_fyum + H_xttkch;
	vec4 H_nzxhnp = atan(H_27h57a);
	vec4 H_jrwraf = H_27h57a + H_nzxhnp;
	vec4 H_9ccpbm = sinh(H_jrwraf);
	vec4 H_iukhwg = H_9ccpbm + H_jrwraf;
	vec4 H_t95rkq = cosh(H_iukhwg);
	vec4 H_26o6hf = H_iukhwg + H_t95rkq;
	vec4 H_9d78cj = tanh(H_26o6hf);
	vec4 H_49fyhm = H_26o6hf + H_9d78cj;
	vec4 H_sricuv = asinh(H_49fyhm);
	vec4 H_bfg9ms = H_49fyhm + H_sricuv;
	vec4 H_onqi3g = acosh(H_bfg9ms);
	vec4 H_5yaqxs = H_bfg9ms + H_onqi3g;
	vec4 H_lkv4ho = atanh(H_5yaqxs);
	vec4 H_f8j5vq = H_5yaqxs + H_lkv4ho;
	vec4 H_2mywoc = pow(H_f8j5vq, H_f8j5vq);
	vec4 H_tgc07q = H_2mywoc + H_f8j5vq;
	vec4 H_qpu2a = exp(H_tgc07q);
	vec4 H_dk4dcj = H_qpu2a + H_tgc07q;
	vec4 H_9xbaf = log(H_dk4dcj);
	vec4 H_svrpa = H_9xbaf + H_dk4dcj;
	vec4 H_ac2bc = exp2(H_svrpa);
	vec4 H_katd4g = H_ac2bc + H_svrpa;
	vec4 H_dsrnja = log2(H_katd4g);
	vec4 H_2xmg6e = H_dsrnja + H_katd4g;
	vec4 H_qojjv = sqrt(H_2xmg6e);
	vec4 H_823mgg = H_2xmg6e + H_qojjv;
	vec4 H_lhpqhc = inversesqrt(H_823mgg);
	vec4 H_vu6cwi = H_823mgg + H_lhpqhc;
	vec4 H_hybov = abs(H_vu6cwi);
	vec4 H_ls6j7z = H_hybov + H_vu6cwi;
	vec4 H_497jwu = sign(H_ls6j7z);
	vec4 H_8q4sa = H_497jwu + H_ls6j7z;
	vec4 H_4r9tqn = floor(H_8q4sa);
	vec4 H_cq21og = H_4r9tqn + H_8q4sa;
	vec4 H_pnd8en = ceil(H_cq21og);
	vec4 H_5ihndv = H_cq21og + H_pnd8en;
	vec4 H_0fqsuy = fract(H_5ihndv);
	vec4 H_0fwhsb = H_0fqsuy + H_5ihndv;
	vec4 H_chemma = mod(H_0fwhsb, H_0fwhsb);
	vec4 H_4b0dru = H_0fwhsb + H_chemma;
	vec4 H_6twtmm = mod(H_4b0dru, H_4b0dru.xxxx);
	vec4 H_fc6qim = H_4b0dru + H_6twtmm;
	vec4 H_4ynrbx = min(H_fc6qim, uv4);
	vec4 H_qme0uc = H_4ynrbx + H_fc6qim;
	vec4 H_4mh53o = max(H_qme0uc, uv4);
	vec4 H_d1n5jt = H_4mh53o + H_qme0uc;
	vec4 H_2g9xs = clamp(H_d1n5jt, uv4, uv4);
	vec4 H_hnouuf = H_2g9xs + H_d1n5jt;
	vec4 H_iz8nxl = mix(H_hnouuf, H_hnouuf, H_hnouuf);
	vec4 H_o2jgoh = H_hnouuf + H_iz8nxl;
	vec4 H_gaxasp = step(H_o2jgoh, H_o2jgoh);
	vec4 H_3ou1m = H_gaxasp + H_o2jgoh;
	vec4 H_67nxre = smoothstep(H_3ou1m, H_3ou1m, H_3ou1m);
	vec4 H_0t4vln = H_3ou1m + H_67nxre;
	vec4 H_1vz1wq = step(uf, H_0t4vln);
	vec4 H_xcgc5f = H_0t4vln + H_1vz1wq;
	vec4 H_o7jeak = smoothstep(uf, uf, H_xcgc5f);
	vec4 H_b9n64q = H_o7jeak + H_xcgc5f;
	vec4 H_q3slgi = normalize(H_b9n64q);
	vec4 H_3jo1tj = H_b9n64q + H_q3slgi;
	vec4 H_lrjeix = faceforward(H_3jo1tj, H_3jo1tj, H_3jo1tj);
	vec4 H_tankrk = H_3jo1tj + H_lrjeix;
	vec4 H_x6ffun = reflect(H_tankrk, H_tankrk);
	vec4 H_lwyi2i = H_tankrk + H_x6ffun;
	vec4 H_uubbzb = refract(H_lwyi2i, H_lwyi2i, uf);
	vec4 H_bwor = H_lwyi2i + H_uubbzb;
	vec4 H_2802gi = dFdx(H_bwor);
	vec4 H_cbjb = H_2802gi + H_bwor;
	vec4 H_36po = dFdy(H_cbjb);
	vec4 H_bn7jta = H_36po + H_cbjb;
	vec4 H_tzraew = fwidth(H_bn7jta);
	vec4 H_fzc38q = H_bn7jta + H_tzraew;
	bvec4 H_gnurdt = lessThan(H_fzc38q, uv4);
	bool H_jzivur = any(H_gnurdt);
	bvec4 H_qykp4o = lessThanEqual(H_fzc38q, uv4);
	bool H_lxg04n = any(H_qykp4o);
	bool H_e65ujj = H_jzivur && H_lxg04n;
	bvec4 H_po3x9e = greaterThan(H_fzc38q, uv4);
	bool H_smlg6k = any(H_po3x9e);
	bool H_72o0hj = H_e65ujj && H_smlg6k;
	bvec4 H_h7acak = greaterThanEqual(H_fzc38q, uv4);
	bool H_xmtkou = any(H_h7acak);
	bool H_rio2t = H_72o0hj && H_xmtkou;
	bvec4 H_vlocan = equal(ub41, ub42);
	bool H_by51mk = any(H_vlocan);
	bool H_dpz2rs = H_rio2t && H_by51mk;
	bvec4 H_e6ku4t = notEqual(ub41, ub42);
	bool H_rjqzlx = any(H_e6ku4t);
	bool H_1f = H_dpz2rs && H_rjqzlx;
	bool H_u0wve = any(ub41);
	bool H_8lgm1k = H_1f && H_u0wve;
	bool H_f4b5uh = all(ub41);
	bool H_2t4w5q = H_8lgm1k && H_f4b5uh;
	bvec4 H_db60wu = not(ub41);
	bool H_hpec3a = any(H_db60wu);
	bool H_3ewbjk = H_2t4w5q && H_hpec3a;
	int H_ngz3vc = H_h8ktht + ui;
	int H_l1vuw = H_h8ktht * H_ngz3vc;
	int H_2knscd = H_l1vuw - ui;
	int H_rq4ows = H_2knscd / H_h8ktht;
	int H_xtc1vg = H_rq4ows % ui;
	bool H_ry3ksp = H_xtc1vg == C_2;
	int H_3j3nrk = H_xtc1vg + C_1;
	int _L = H_ry3ksp ? C_0 : H_3j3nrk;
	float H_6ra9oe = uf + uf;
	float H_eccx = H_6ra9oe * uf;
	float H_my73qz = H_eccx - uf;
	float H_1umaut = H_my73qz / uf;
	float H_pebi7n = length(H_fzc38q);
	float H_5868mb = H_1umaut + H_pebi7n;
	float H_9xgw8z = dot(H_fzc38q, H_fzc38q);
	float H_ahac5a = H_5868mb + H_9xgw8z;
	float H_7kv9h = H_ahac5a * uf;
	float H_xz4r = H_7kv9h + H_ahac5a;
	vec3 H_ku1yjn = cross(H_fzc38q.xyz, H_fzc38q.xyz);
	float H_yu = H_ku1yjn.x + H_xz4r;
	bool H_kot1tw = H_yu == uf;
	bool H_kzsh = H_yu != uf;
	bool H_ppnz8y = H_yu != C_2d0;
	bool H_qnzi2l = H_kzsh && H_ppnz8y;
	bool H_247rn = H_kot1tw || H_qnzi2l;
	float H_94a7zi = H_yu + C_1d0;
	float select = H_247rn ? H_94a7zi : H_yu;
	vec4 H_c1z5nn = vec4(select);
	int H_sigq8q = ui & _L;
	int H_s9dupe = H_sigq8q | C_66;
	int H_dz351k = H_s9dupe ^ ui;
	int H_8w7dri = H_dz351k % C_17;
	int H_qlaxc = H_8w7dri >> C_2;
	int H_sf9rny = H_qlaxc << ui;
	int H_8iiwvi = ~(H_sf9rny);
	float H_yrfrlx = float(H_8iiwvi);
	vec4 H_upvu3e = vec4(H_yrfrlx);
	vec4 H_hfe3lx = H_c1z5nn + H_upvu3e;
	vec4 Ll_FragColor = H_fzc38q + H_hfe3lx;
	vec4 select1 = H_3ewbjk ? H_fzc38q : Ll_FragColor;
	gl_FragColor = select1;
	
}

