
Top IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer
@uiv4 = external addrspace(2) constant <4 x i32>
@ub = external addrspace(2) constant i1

define fastcc void @main() {
entry:
  %constructed75 = alloca <4 x float>
  %constructed = alloca <4 x float>
  %ternary = alloca <4 x float>
  %f = alloca float
  %b = alloca i1
  %i = alloca i32
  %v = alloca <4 x float>
  %0 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v1 = call <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float> %0)
  store <4 x float> %v1, <4 x float>* %v
  %1 = load <4 x float>* %v
  %2 = call <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float> %1)
  %3 = load <4 x float>* %v
  %v2 = fadd <4 x float> %3, %2
  store <4 x float> %v2, <4 x float>* %v
  %4 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %5 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i3 = mul i32 %4, %5
  store i32 %i3, i32* %i
  %6 = load <4 x float>* %v
  %7 = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %6)
  %8 = load <4 x float>* %v
  %v4 = fadd <4 x float> %8, %7
  store <4 x float> %v4, <4 x float>* %v
  %9 = load <4 x float>* %v
  %10 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %9)
  %11 = load <4 x float>* %v
  %v5 = fadd <4 x float> %11, %10
  store <4 x float> %v5, <4 x float>* %v
  %12 = load <4 x float>* %v
  %13 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %12)
  %14 = load <4 x float>* %v
  %v6 = fadd <4 x float> %14, %13
  store <4 x float> %v6, <4 x float>* %v
  %15 = load <4 x float>* %v
  %16 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %15)
  %17 = load <4 x float>* %v
  %v7 = fadd <4 x float> %17, %16
  store <4 x float> %v7, <4 x float>* %v
  %18 = load <4 x float>* %v
  %19 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %18)
  %20 = load <4 x float>* %v
  %v8 = fadd <4 x float> %20, %19
  store <4 x float> %v8, <4 x float>* %v
  %21 = load <4 x float>* %v
  %22 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %21)
  %23 = load <4 x float>* %v
  %v9 = fadd <4 x float> %23, %22
  store <4 x float> %v9, <4 x float>* %v
  %24 = load <4 x float>* %v
  %25 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %24)
  %26 = load <4 x float>* %v
  %v10 = fadd <4 x float> %26, %25
  store <4 x float> %v10, <4 x float>* %v
  %27 = load <4 x float>* %v
  %28 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %27)
  %29 = load <4 x float>* %v
  %v11 = fadd <4 x float> %29, %28
  store <4 x float> %v11, <4 x float>* %v
  %30 = load <4 x float>* %v
  %31 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %30)
  %32 = load <4 x float>* %v
  %v12 = fadd <4 x float> %32, %31
  store <4 x float> %v12, <4 x float>* %v
  %33 = load <4 x float>* %v
  %34 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %33)
  %35 = load <4 x float>* %v
  %v13 = fadd <4 x float> %35, %34
  store <4 x float> %v13, <4 x float>* %v
  %36 = load <4 x float>* %v
  %37 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %36)
  %38 = load <4 x float>* %v
  %v14 = fadd <4 x float> %38, %37
  store <4 x float> %v14, <4 x float>* %v
  %39 = load <4 x float>* %v
  %40 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %39)
  %41 = load <4 x float>* %v
  %v15 = fadd <4 x float> %41, %40
  store <4 x float> %v15, <4 x float>* %v
  %42 = load <4 x float>* %v
  %43 = load <4 x float>* %v
  %44 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %42, <4 x float> %43)
  %45 = load <4 x float>* %v
  %v16 = fadd <4 x float> %45, %44
  store <4 x float> %v16, <4 x float>* %v
  %46 = load <4 x float>* %v
  %47 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %46)
  %48 = load <4 x float>* %v
  %v17 = fadd <4 x float> %48, %47
  store <4 x float> %v17, <4 x float>* %v
  %49 = load <4 x float>* %v
  %50 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %49)
  %51 = load <4 x float>* %v
  %v18 = fadd <4 x float> %51, %50
  store <4 x float> %v18, <4 x float>* %v
  %52 = load <4 x float>* %v
  %53 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %52)
  %54 = load <4 x float>* %v
  %v19 = fadd <4 x float> %54, %53
  store <4 x float> %v19, <4 x float>* %v
  %55 = load <4 x float>* %v
  %56 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %55)
  %57 = load <4 x float>* %v
  %v20 = fadd <4 x float> %57, %56
  store <4 x float> %v20, <4 x float>* %v
  %58 = load <4 x float>* %v
  %59 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %58)
  %60 = load <4 x float>* %v
  %v21 = fadd <4 x float> %60, %59
  store <4 x float> %v21, <4 x float>* %v
  %61 = load <4 x float>* %v
  %62 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %61)
  %63 = load <4 x float>* %v
  %v22 = fadd <4 x float> %63, %62
  store <4 x float> %v22, <4 x float>* %v
  %64 = load <4 x float>* %v
  %65 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %64)
  %66 = load <4 x float>* %v
  %v23 = fadd <4 x float> %66, %65
  store <4 x float> %v23, <4 x float>* %v
  %67 = load <4 x float>* %v
  %68 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %67)
  %69 = load <4 x float>* %v
  %v24 = fadd <4 x float> %69, %68
  store <4 x float> %v24, <4 x float>* %v
  %70 = load <4 x float>* %v
  %71 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %70)
  %72 = load <4 x float>* %v
  %v25 = fadd <4 x float> %72, %71
  store <4 x float> %v25, <4 x float>* %v
  %73 = load <4 x float>* %v
  %74 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %73)
  %75 = load <4 x float>* %v
  %v26 = fadd <4 x float> %75, %74
  store <4 x float> %v26, <4 x float>* %v
  %76 = load <4 x float>* %v
  %77 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %76)
  %78 = load <4 x float>* %v
  %v27 = fadd <4 x float> %78, %77
  store <4 x float> %v27, <4 x float>* %v
  %79 = load <4 x float>* %v
  %80 = load <4 x float>* %v
  %81 = frem <4 x float> %79, %80
  %82 = load <4 x float>* %v
  %v28 = fadd <4 x float> %82, %81
  store <4 x float> %v28, <4 x float>* %v
  %83 = load <4 x float>* %v
  %84 = load <4 x float>* %v
  %85 = extractelement <4 x float> %84, i32 0
  %86 = insertelement <4 x float> undef, float %85, i32 0
  %87 = insertelement <4 x float> %86, float %85, i32 1
  %88 = insertelement <4 x float> %87, float %85, i32 2
  %89 = insertelement <4 x float> %88, float %85, i32 3
  %90 = frem <4 x float> %83, %89
  %91 = load <4 x float>* %v
  %v29 = fadd <4 x float> %91, %90
  store <4 x float> %v29, <4 x float>* %v
  %92 = load <4 x float>* %v
  %93 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %94 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %92, <4 x float> %93)
  %95 = load <4 x float>* %v
  %v30 = fadd <4 x float> %95, %94
  store <4 x float> %v30, <4 x float>* %v
  %96 = load <4 x float>* %v
  %97 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %98 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %96, <4 x float> %97)
  %99 = load <4 x float>* %v
  %v31 = fadd <4 x float> %99, %98
  store <4 x float> %v31, <4 x float>* %v
  %100 = load <4 x float>* %v
  %101 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %102 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %103 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %100, <4 x float> %101, <4 x float> %102)
  %104 = load <4 x float>* %v
  %v32 = fadd <4 x float> %104, %103
  store <4 x float> %v32, <4 x float>* %v
  %105 = load <4 x float>* %v
  %106 = load <4 x float>* %v
  %107 = load <4 x float>* %v
  %108 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %105, <4 x float> %106, <4 x float> %107)
  %109 = load <4 x float>* %v
  %v33 = fadd <4 x float> %109, %108
  store <4 x float> %v33, <4 x float>* %v
  %110 = load <4 x float>* %v
  %111 = load <4 x float>* %v
  %112 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %110, <4 x float> %111)
  %113 = load <4 x float>* %v
  %v34 = fadd <4 x float> %113, %112
  store <4 x float> %v34, <4 x float>* %v
  %114 = load <4 x float>* %v
  %115 = load <4 x float>* %v
  %116 = load <4 x float>* %v
  %117 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %114, <4 x float> %115, <4 x float> %116)
  %118 = load <4 x float>* %v
  %v35 = fadd <4 x float> %118, %117
  store <4 x float> %v35, <4 x float>* %v
  %119 = load float addrspace(2)* @uf, !gla.uniform !4
  %120 = load <4 x float>* %v
  %121 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %119, <4 x float> %120)
  %122 = load <4 x float>* %v
  %v36 = fadd <4 x float> %122, %121
  store <4 x float> %v36, <4 x float>* %v
  %123 = load float addrspace(2)* @uf, !gla.uniform !4
  %124 = load float addrspace(2)* @uf, !gla.uniform !4
  %125 = load <4 x float>* %v
  %126 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %123, float %124, <4 x float> %125)
  %127 = load <4 x float>* %v
  %v37 = fadd <4 x float> %127, %126
  store <4 x float> %v37, <4 x float>* %v
  %128 = load <4 x float>* %v
  %129 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %128)
  %130 = load <4 x float>* %v
  %v38 = fadd <4 x float> %130, %129
  store <4 x float> %v38, <4 x float>* %v
  %131 = load <4 x float>* %v
  %132 = load <4 x float>* %v
  %133 = load <4 x float>* %v
  %134 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %131, <4 x float> %132, <4 x float> %133)
  %135 = load <4 x float>* %v
  %v39 = fadd <4 x float> %135, %134
  store <4 x float> %v39, <4 x float>* %v
  %136 = load <4 x float>* %v
  %137 = load <4 x float>* %v
  %138 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %136, <4 x float> %137)
  %139 = load <4 x float>* %v
  %v40 = fadd <4 x float> %139, %138
  store <4 x float> %v40, <4 x float>* %v
  %140 = load <4 x float>* %v
  %141 = load <4 x float>* %v
  %142 = load float addrspace(2)* @uf, !gla.uniform !4
  %143 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %140, <4 x float> %141, float %142)
  %144 = load <4 x float>* %v
  %v41 = fadd <4 x float> %144, %143
  store <4 x float> %v41, <4 x float>* %v
  %145 = load <4 x float>* %v
  %146 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %145)
  %147 = load <4 x float>* %v
  %v42 = fadd <4 x float> %147, %146
  store <4 x float> %v42, <4 x float>* %v
  %148 = load <4 x float>* %v
  %149 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %148)
  %150 = load <4 x float>* %v
  %v43 = fadd <4 x float> %150, %149
  store <4 x float> %v43, <4 x float>* %v
  %151 = load <4 x float>* %v
  %152 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %151)
  %153 = load <4 x float>* %v
  %v44 = fadd <4 x float> %153, %152
  store <4 x float> %v44, <4 x float>* %v
  %154 = load <4 x float>* %v
  %155 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %156 = fcmp olt <4 x float> %154, %155
  %b45 = call i1 @llvm.gla.any.v4i1(<4 x i1> %156)
  store i1 %b45, i1* %b
  %157 = load i1* %b
  %158 = load <4 x float>* %v
  %159 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %160 = fcmp ole <4 x float> %158, %159
  %161 = call i1 @llvm.gla.any.v4i1(<4 x i1> %160)
  %b46 = and i1 %157, %161
  store i1 %b46, i1* %b
  %162 = load i1* %b
  %163 = load <4 x float>* %v
  %164 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %165 = fcmp ogt <4 x float> %163, %164
  %166 = call i1 @llvm.gla.any.v4i1(<4 x i1> %165)
  %b47 = and i1 %162, %166
  store i1 %b47, i1* %b
  %167 = load i1* %b
  %168 = load <4 x float>* %v
  %169 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %170 = fcmp oge <4 x float> %168, %169
  %171 = call i1 @llvm.gla.any.v4i1(<4 x i1> %170)
  %b48 = and i1 %167, %171
  store i1 %b48, i1* %b
  %172 = load i1* %b
  %173 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %174 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %175 = icmp eq <4 x i1> %173, %174
  %176 = call i1 @llvm.gla.any.v4i1(<4 x i1> %175)
  %b49 = and i1 %172, %176
  store i1 %b49, i1* %b
  %177 = load i1* %b
  %178 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %179 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %180 = icmp ne <4 x i1> %178, %179
  %181 = call i1 @llvm.gla.any.v4i1(<4 x i1> %180)
  %b50 = and i1 %177, %181
  store i1 %b50, i1* %b
  %182 = load i1* %b
  %183 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %184 = call i1 @llvm.gla.any.v4i1(<4 x i1> %183)
  %b51 = and i1 %182, %184
  store i1 %b51, i1* %b
  %185 = load i1* %b
  %186 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %187 = call i1 @llvm.gla.all.v4i1(<4 x i1> %186)
  %b52 = and i1 %185, %187
  store i1 %b52, i1* %b
  %188 = load i1* %b
  %189 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %190 = xor <4 x i1> %189, <i1 true, i1 true, i1 true, i1 true>
  %191 = call i1 @llvm.gla.any.v4i1(<4 x i1> %190)
  %b53 = and i1 %188, %191
  store i1 %b53, i1* %b
  %192 = load i32* %i
  %193 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %194 = add i32 %192, %193
  %195 = load i32* %i
  %196 = mul i32 %194, %195
  %197 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %198 = sub i32 %196, %197
  %199 = load i32* %i
  %i54 = sdiv i32 %198, %199
  store i32 %i54, i32* %i
  %200 = load i32* %i
  %201 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i55 = srem i32 %200, %201
  store i32 %i55, i32* %i
  %202 = load i32* %i
  %203 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %204 = icmp eq i32 %202, %203
  %205 = load i32* %i
  %206 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %207 = icmp ne i32 %205, %206
  %208 = load i32* %i
  %209 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %210 = icmp eq i32 %208, %209
  %211 = and i1 %207, %210
  %212 = load i32* %i
  %213 = icmp ne i32 %212, 2
  %214 = xor i1 %211, %213
  %215 = or i1 %204, %214
  br i1 %215, label %then, label %ifmerge

then:                                             ; preds = %entry
  %216 = load i32* %i
  %i56 = add i32 %216, 1
  store i32 %i56, i32* %i
  br label %ifmerge

ifmerge:                                          ; preds = %entry, %then
  %217 = load float addrspace(2)* @uf, !gla.uniform !4
  %218 = load float addrspace(2)* @uf, !gla.uniform !4
  %219 = fadd float %217, %218
  %220 = load float addrspace(2)* @uf, !gla.uniform !4
  %221 = fmul float %219, %220
  %222 = load float addrspace(2)* @uf, !gla.uniform !4
  %223 = fsub float %221, %222
  %224 = load float addrspace(2)* @uf, !gla.uniform !4
  %f57 = fdiv float %223, %224
  store float %f57, float* %f
  %225 = load <4 x float>* %v
  %226 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %225)
  %227 = load float* %f
  %f58 = fadd float %227, %226
  store float %f58, float* %f
  %228 = load <4 x float>* %v
  %229 = load <4 x float>* %v
  %230 = call float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float> %228, <4 x float> %229)
  %231 = load float* %f
  %f59 = fadd float %231, %230
  store float %f59, float* %f
  %232 = load <4 x float>* %v
  %233 = load <4 x float>* %v
  %234 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %232, <4 x float> %233)
  %235 = load float* %f
  %f60 = fadd float %235, %234
  store float %f60, float* %f
  %236 = load float* %f
  %237 = load float addrspace(2)* @uf, !gla.uniform !4
  %238 = fmul float %236, %237
  %239 = load float* %f
  %f61 = fadd float %239, %238
  store float %f61, float* %f
  %240 = load <4 x float>* %v
  %241 = extractelement <4 x float> %240, i32 0
  %242 = insertelement <3 x float> undef, float %241, i32 0
  %243 = extractelement <4 x float> %240, i32 1
  %244 = insertelement <3 x float> %242, float %243, i32 1
  %245 = extractelement <4 x float> %240, i32 2
  %246 = insertelement <3 x float> %244, float %245, i32 2
  %247 = load <4 x float>* %v
  %248 = extractelement <4 x float> %247, i32 0
  %249 = insertelement <3 x float> undef, float %248, i32 0
  %250 = extractelement <4 x float> %247, i32 1
  %251 = insertelement <3 x float> %249, float %250, i32 1
  %252 = extractelement <4 x float> %247, i32 2
  %253 = insertelement <3 x float> %251, float %252, i32 2
  %254 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %246, <3 x float> %253)
  %255 = extractelement <3 x float> %254, i32 0
  %256 = load float* %f
  %f62 = fadd float %256, %255
  store float %f62, float* %f
  %257 = load float* %f
  %258 = load float addrspace(2)* @uf, !gla.uniform !4
  %259 = fcmp oeq float %257, %258
  %260 = load float* %f
  %261 = load float addrspace(2)* @uf, !gla.uniform !4
  %262 = fcmp one float %260, %261
  %263 = load float* %f
  %264 = fcmp one float %263, 2.000000e+00
  %265 = and i1 %262, %264
  %266 = or i1 %259, %265
  br i1 %266, label %then63, label %ifmerge65

then63:                                           ; preds = %ifmerge
  %267 = load float* %f
  %f64 = fadd float %267, 1.000000e+00
  store float %f64, float* %f
  br label %ifmerge65

ifmerge65:                                        ; preds = %ifmerge, %then63
  %268 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %269 = load i32* %i
  %i66 = and i32 %269, %268
  store i32 %i66, i32* %i
  %270 = load i32* %i
  %i67 = or i32 %270, 66
  store i32 %i67, i32* %i
  %271 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %272 = load i32* %i
  %i68 = xor i32 %272, %271
  store i32 %i68, i32* %i
  %273 = load i32* %i
  %i69 = srem i32 %273, 17
  store i32 %i69, i32* %i
  %274 = load i32* %i
  %i70 = ashr i32 %274, 2
  store i32 %i70, i32* %i
  %275 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %276 = load i32* %i
  %i71 = shl i32 %276, %275
  store i32 %i71, i32* %i
  %277 = load i32* %i
  %i72 = xor i32 %277, -1
  store i32 %i72, i32* %i
  %278 = load i1* %b
  %b73 = xor i1 %278, true
  store i1 %b73, i1* %b
  %279 = load i1* %b
  br i1 %279, label %then74, label %else

then74:                                           ; preds = %ifmerge65
  %280 = load i32* %i
  %281 = sitofp i32 %280 to float
  %282 = load <4 x float>* %constructed
  %283 = insertelement <4 x float> undef, float %281, i32 0
  %284 = insertelement <4 x float> %283, float %281, i32 1
  %285 = insertelement <4 x float> %284, float %281, i32 2
  %286 = insertelement <4 x float> %285, float %281, i32 3
  %287 = load float* %f
  %288 = load <4 x float>* %constructed75
  %289 = insertelement <4 x float> undef, float %287, i32 0
  %290 = insertelement <4 x float> %289, float %287, i32 1
  %291 = insertelement <4 x float> %290, float %287, i32 2
  %292 = insertelement <4 x float> %291, float %287, i32 3
  %293 = fadd <4 x float> %286, %292
  %294 = load <4 x float>* %v
  %ternary76 = fadd <4 x float> %293, %294
  store <4 x float> %ternary76, <4 x float>* %ternary
  br label %ifmerge78

else:                                             ; preds = %ifmerge65
  %ternary77 = load <4 x float>* %v
  store <4 x float> %ternary77, <4 x float>* %ternary
  br label %ifmerge78

ifmerge78:                                        ; preds = %else, %then74
  %gl_FragColor = load <4 x float>* %ternary
  store <4 x float> %gl_FragColor, <4 x float>* @gl_FragColor
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %ifmerge78
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}


Bottom IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer

define fastcc void @main() {
entry:
  %0 = load <4 x float> addrspace(2)* @uv4, align 16, !gla.uniform !1
  %1 = fmul <4 x float> %0, <float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000>
  %2 = fmul <4 x float> %1, <float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000>
  %v2 = fadd <4 x float> %1, %2
  %3 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i3 = mul i32 %3, %3
  %4 = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %v2)
  %v4 = fadd <4 x float> %4, %v2
  %5 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %v4)
  %v5 = fadd <4 x float> %5, %v4
  %6 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %v5)
  %v6 = fadd <4 x float> %6, %v5
  %7 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %v6)
  %v7 = fadd <4 x float> %7, %v6
  %8 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %v7)
  %v8 = fadd <4 x float> %8, %v7
  %9 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %v8)
  %v9 = fadd <4 x float> %9, %v8
  %10 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %v9)
  %v10 = fadd <4 x float> %10, %v9
  %11 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %v10)
  %v11 = fadd <4 x float> %11, %v10
  %12 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %v11)
  %v12 = fadd <4 x float> %12, %v11
  %13 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %v12)
  %v13 = fadd <4 x float> %13, %v12
  %14 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %v13)
  %v14 = fadd <4 x float> %14, %v13
  %15 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %v14)
  %v15 = fadd <4 x float> %15, %v14
  %16 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %v15, <4 x float> %v15)
  %v16 = fadd <4 x float> %16, %v15
  %17 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %v16)
  %v17 = fadd <4 x float> %17, %v16
  %18 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %v17)
  %v18 = fadd <4 x float> %18, %v17
  %19 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %v18)
  %v19 = fadd <4 x float> %19, %v18
  %20 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %v19)
  %v20 = fadd <4 x float> %20, %v19
  %21 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %v20)
  %v21 = fadd <4 x float> %21, %v20
  %22 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %v21)
  %v22 = fadd <4 x float> %22, %v21
  %23 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %v22)
  %v23 = fadd <4 x float> %23, %v22
  %24 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %v23)
  %v24 = fadd <4 x float> %24, %v23
  %25 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %v24)
  %v25 = fadd <4 x float> %25, %v24
  %26 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %v25)
  %v26 = fadd <4 x float> %26, %v25
  %27 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %v26)
  %v27 = fadd <4 x float> %27, %v26
  %28 = frem <4 x float> %v27, %v27
  %v28 = fadd <4 x float> %28, %v27
  %29 = call <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float> %v28, <4 x i32> zeroinitializer)
  %30 = frem <4 x float> %v28, %29
  %v29 = fadd <4 x float> %30, %v28
  %31 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %v29, <4 x float> %0)
  %v30 = fadd <4 x float> %31, %v29
  %32 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %v30, <4 x float> %0)
  %v31 = fadd <4 x float> %32, %v30
  %33 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %v31, <4 x float> %0, <4 x float> %0)
  %v32 = fadd <4 x float> %33, %v31
  %34 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %v32, <4 x float> %v32, <4 x float> %v32)
  %v33 = fadd <4 x float> %34, %v32
  %35 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %v33, <4 x float> %v33)
  %v34 = fadd <4 x float> %35, %v33
  %36 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %v34, <4 x float> %v34, <4 x float> %v34)
  %v35 = fadd <4 x float> %36, %v34
  %37 = load float addrspace(2)* @uf, align 4, !gla.uniform !4
  %38 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %37, <4 x float> %v35)
  %v36 = fadd <4 x float> %v35, %38
  %39 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %37, float %37, <4 x float> %v36)
  %v37 = fadd <4 x float> %v36, %39
  %40 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %v37)
  %v38 = fadd <4 x float> %v37, %40
  %41 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %v38, <4 x float> %v38, <4 x float> %v38)
  %v39 = fadd <4 x float> %v38, %41
  %42 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %v39, <4 x float> %v39)
  %v40 = fadd <4 x float> %v39, %42
  %43 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %v40, <4 x float> %v40, float %37)
  %v41 = fadd <4 x float> %v40, %43
  %44 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %v41)
  %v42 = fadd <4 x float> %v41, %44
  %45 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %v42)
  %v43 = fadd <4 x float> %v42, %45
  %46 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %v43)
  %v44 = fadd <4 x float> %v43, %46
  %47 = call <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float> %v44, <3 x i32> <i32 0, i32 1, i32 2>)
  %48 = fcmp olt <4 x float> %v44, %0
  %b45 = call i1 @llvm.gla.any.v4i1(<4 x i1> %48)
  %49 = fcmp ole <4 x float> %v44, %0
  %50 = call i1 @llvm.gla.any.v4i1(<4 x i1> %49)
  %b46 = and i1 %b45, %50
  %51 = fcmp ogt <4 x float> %v44, %0
  %52 = call i1 @llvm.gla.any.v4i1(<4 x i1> %51)
  %b47 = and i1 %b46, %52
  %53 = fcmp oge <4 x float> %v44, %0
  %54 = call i1 @llvm.gla.any.v4i1(<4 x i1> %53)
  %b48 = and i1 %b47, %54
  %55 = load <4 x i1> addrspace(2)* @ub41, align 4, !gla.uniform !5
  %56 = load <4 x i1> addrspace(2)* @ub42, align 4, !gla.uniform !6
  %57 = icmp eq <4 x i1> %55, %56
  %58 = call i1 @llvm.gla.any.v4i1(<4 x i1> %57)
  %b49 = and i1 %b48, %58
  %59 = icmp ne <4 x i1> %55, %56
  %60 = call i1 @llvm.gla.any.v4i1(<4 x i1> %59)
  %b50 = and i1 %b49, %60
  %61 = call i1 @llvm.gla.any.v4i1(<4 x i1> %55)
  %b51 = and i1 %b50, %61
  %62 = call i1 @llvm.gla.all.v4i1(<4 x i1> %55)
  %b52 = and i1 %b51, %62
  %63 = xor <4 x i1> %55, <i1 true, i1 true, i1 true, i1 true>
  %64 = call i1 @llvm.gla.any.v4i1(<4 x i1> %63)
  %b53 = and i1 %b52, %64
  %65 = add i32 %i3, %3
  %66 = mul i32 %65, %i3
  %67 = sub i32 %66, %3
  %i54 = sdiv i32 %67, %i3
  %i55 = srem i32 %i54, %3
  %68 = icmp eq i32 %i55, 2
  %i56 = add i32 %i55, 1
  %.i56 = select i1 %68, i32 0, i32 %i56
  %69 = fadd float %37, %37
  %70 = fmul float %37, %69
  %71 = fsub float %70, %37
  %f57 = fdiv float %71, %37
  %72 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %v44)
  %f58 = fadd float %f57, %72
  %73 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %v44, <4 x float> %v44)
  %f60 = fadd float %f58, %73
  %74 = fmul float %37, %f60
  %f61 = fadd float %f60, %74
  %75 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %47, <3 x float> %47)
  %76 = extractelement <3 x float> %75, i32 0
  %f62 = fadd float %76, %f61
  %77 = fcmp oeq float %f62, %37
  %78 = fcmp one float %f62, %37
  %79 = fcmp one float %f62, 2.000000e+00
  %80 = and i1 %78, %79
  %81 = or i1 %77, %80
  %f64 = fadd float %f62, 1.000000e+00
  %select79 = select i1 %81, float %f64, float %f62
  %82 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %select79, <4 x i32> zeroinitializer)
  %83 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i66 = and i32 %83, %.i56
  %i67 = or i32 %i66, 66
  %i68 = xor i32 %i67, %83
  %i69 = srem i32 %i68, 17
  %i70 = ashr i32 %i69, 2
  %i71 = shl i32 %i70, %83
  %i72 = xor i32 %i71, -1
  %84 = sitofp i32 %i72 to float
  %85 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %84, <4 x i32> zeroinitializer)
  %86 = fadd <4 x float> %85, %82
  %ternary76 = fadd <4 x float> %v44, %86
  %select = select i1 %b53, <4 x float> %v44, <4 x float> %ternary76
  store <4 x float> %select, <4 x float>* @gl_FragColor, align 16
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %entry
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float>, <4 x i32>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float>, <3 x i32>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float, <4 x i32>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}
#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 C_vssely1 = vec4(0.0174533);
const vec4 C_4bmlfm = vec4(57.2958);
const int C_2 = 2;
const int C_1 = 1;
const int C_0 = 0;
const float C_2d0 = 2.0;
const float C_1d0 = 1.0;
const int C_66 = 66;
const int C_17 = 17;

void main()
{
	vec4 H_hgy73b1 = uv4 * C_vssely1;
	vec4 H_9zy93p = (H_hgy73b1 * C_4bmlfm) + H_hgy73b1;
	int H_h8ktht1 = ui * ui;
	vec4 H_3acemg1 = H_9zy93p + sin(H_9zy93p);
	vec4 H_477lm1 = H_3acemg1 + cos(H_3acemg1);
	vec4 H_m1hprk1 = H_477lm1 + tan(H_477lm1);
	vec4 H_edsua3 = H_m1hprk1 + asin(H_m1hprk1);
	vec4 H_h444t31 = H_edsua3 + acos(H_edsua3);
	vec4 H_lte5ga = H_h444t31 + atan(H_h444t31);
	vec4 H_ljhpu01 = H_lte5ga + sinh(H_lte5ga);
	vec4 H_ooznea = H_ljhpu01 + cosh(H_ljhpu01);
	vec4 H_auhvob1 = H_ooznea + tanh(H_ooznea);
	vec4 H_6fgul7 = H_auhvob1 + asinh(H_auhvob1);
	vec4 H_xwfalw = H_6fgul7 + acosh(H_6fgul7);
	vec4 H_5umpfi1 = H_xwfalw + atanh(H_xwfalw);
	vec4 H_t2axin = H_5umpfi1 + pow(H_5umpfi1, H_5umpfi1);
	vec4 H_e5m0nc = H_t2axin + exp(H_t2axin);
	vec4 H_70xjiu = H_e5m0nc + log(H_e5m0nc);
	vec4 H_w4d9351 = H_70xjiu + exp2(H_70xjiu);
	vec4 H_9pg9nm = H_w4d9351 + log2(H_w4d9351);
	vec4 H_5sev2h1 = H_9pg9nm + sqrt(H_9pg9nm);
	vec4 H_fnuvwz = H_5sev2h1 + inversesqrt(H_5sev2h1);
	vec4 H_pdp3321 = H_fnuvwz + abs(H_fnuvwz);
	vec4 H_e0xje2 = H_pdp3321 + sign(H_pdp3321);
	vec4 H_vpnnm9 = H_e0xje2 + floor(H_e0xje2);
	vec4 H_qvqsxv1 = H_vpnnm9 + ceil(H_vpnnm9);
	vec4 H_x7an1a = H_qvqsxv1 + fract(H_qvqsxv1);
	vec4 H_8xggpy1 = mod(H_x7an1a, H_x7an1a);
	vec4 H_2dr5td = H_8xggpy1 + H_x7an1a;
	vec4 H_8okke31 = mod(H_2dr5td, H_2dr5td.xxxx);
	vec4 H_3d5om6 = H_2dr5td + H_8okke31;
	vec4 H_2p4x99 = H_3d5om6 + min(H_3d5om6, uv4);
	vec4 H_wf82ce1 = H_2p4x99 + max(H_2p4x99, uv4);
	vec4 H_itgwo91 = H_wf82ce1 + clamp(H_wf82ce1, uv4, uv4);
	vec4 H_h3r3us1 = H_itgwo91 + mix(H_itgwo91, H_itgwo91, H_itgwo91);
	vec4 H_lfzxvv = H_h3r3us1 + step(H_h3r3us1, H_h3r3us1);
	vec4 H_f0ucn9 = H_lfzxvv + smoothstep(H_lfzxvv, H_lfzxvv, H_lfzxvv);
	vec4 H_4cycpc = H_f0ucn9 + step(uf, H_f0ucn9);
	vec4 H_n3ylrb = H_4cycpc + smoothstep(uf, uf, H_4cycpc);
	vec4 H_u95e2i = H_n3ylrb + normalize(H_n3ylrb);
	vec4 H_5h6m1q1 = H_u95e2i + faceforward(H_u95e2i, H_u95e2i, H_u95e2i);
	vec4 H_ahiu3l = H_5h6m1q1 + reflect(H_5h6m1q1, H_5h6m1q1);
	vec4 H_wfm2xr = H_ahiu3l + refract(H_ahiu3l, H_ahiu3l, uf);
	vec4 H_pbjqt31 = H_wfm2xr + dFdx(H_wfm2xr);
	vec4 H_ig6xjj = H_pbjqt31 + dFdy(H_pbjqt31);
	vec4 H_99ufny1 = H_ig6xjj + fwidth(H_ig6xjj);
	bool H_hwysnq1 = ((any(lessThan(H_99ufny1, uv4)) && any(lessThanEqual(H_99ufny1, uv4))) && any(greaterThan(H_99ufny1, uv4))) && any(greaterThanEqual(H_99ufny1, uv4));
	int H_gxb34c1 = ((((H_h8ktht1 + ui) * H_h8ktht1) - ui) / H_h8ktht1) % ui;
	float H_v3t13j = (((((uf + uf) * uf) - uf) / uf) + length(H_99ufny1)) + dot(H_99ufny1, H_99ufny1);
	float H_d9rb01 = ((H_v3t13j * uf) + H_v3t13j) + cross(H_99ufny1.xyz, H_99ufny1.xyz).x;
	vec4 H_yzkz6l = vec4((((H_d9rb01 == uf) || ((H_d9rb01 != uf) && (H_d9rb01 != C_2d0))) ? (H_d9rb01 + C_1d0) : H_d9rb01)) + vec4((float((~(((((((ui & ((H_gxb34c1 == C_2) ? C_0 : (H_gxb34c1 + C_1))) | C_66) ^ ui) % C_17) >> C_2) << ui))))));
	vec4 select_c1 = (((((H_hwysnq1 && any(equal(ub41, ub42))) && any(notEqual(ub41, ub42))) && any(ub41)) && all(ub41)) && any((not(ub41)))) ? H_99ufny1 : (H_99ufny1 + H_yzkz6l);
	gl_FragColor = select_c1;
	
}

#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 C_vssely1 = vec4(0.0174533);
const vec4 C_4bmlfm = vec4(57.2958);
const float C_2d0 = 2.0;
const float C_1d0 = 1.0;
const int C_2 = 2;
const int C_1 = 1;
const int C_0 = 0;
const int C_66 = 66;
const int C_17 = 17;

void main()
{
	vec4 H_hgy_c1 = uv4 * C_vssely1;
	vec4 H_uc2 = (H_hgy_c1 * C_4bmlfm) + H_hgy_c1;
	int H_h_c3 = ui * ui;
	vec4 H_uc4 = H_uc2 + sin(H_uc2);
	vec4 H_uc5 = H_uc4 + cos(H_uc4);
	vec4 H_m_c6 = H_uc5 + tan(H_uc5);
	vec4 H_edsua_c7 = H_m_c6 + asin(H_m_c6);
	vec4 H_h_c8 = H_edsua_c7 + acos(H_edsua_c7);
	vec4 H_lte_c9 = H_h_c8 + atan(H_h_c8);
	vec4 H_ljhpu_c10 = H_lte_c9 + sinh(H_lte_c9);
	vec4 H_ooznea_c11 = H_ljhpu_c10 + cosh(H_ljhpu_c10);
	vec4 H_auhvob_c12 = H_ooznea_c11 + tanh(H_ooznea_c11);
	vec4 H_uc13 = H_auhvob_c12 + asinh(H_auhvob_c12);
	vec4 H_xwfalw_c14 = H_uc13 + acosh(H_uc13);
	vec4 H_uc15 = H_xwfalw_c14 + atanh(H_xwfalw_c14);
	vec4 H_t_c16 = H_uc15 + pow(H_uc15, H_uc15);
	vec4 H_e_c17 = H_t_c16 + exp(H_t_c16);
	vec4 H_uc18 = H_e_c17 + log(H_e_c17);
	vec4 H_w_c19 = H_uc18 + exp2(H_uc18);
	vec4 H_uc20 = H_w_c19 + log2(H_w_c19);
	vec4 H_uc21 = H_uc20 + sqrt(H_uc20);
	vec4 H_fnuvwz_c22 = H_uc21 + inversesqrt(H_uc21);
	vec4 H_pdp_c23 = H_fnuvwz_c22 + abs(H_fnuvwz_c22);
	vec4 H_e_c24 = H_pdp_c23 + sign(H_pdp_c23);
	vec4 H_vpnnm_c25 = H_e_c24 + floor(H_e_c24);
	vec4 H_qvqsxv_c26 = H_vpnnm_c25 + ceil(H_vpnnm_c25);
	vec4 H_x_c27 = H_qvqsxv_c26 + fract(H_qvqsxv_c26);
	vec4 H_uc28 = mod(H_x_c27, H_x_c27);
	vec4 H_uc29 = H_uc28 + H_x_c27;
	vec4 H_uc30 = mod(H_uc29, H_uc29.xxxx);
	vec4 H_uc31 = H_uc29 + H_uc30;
	vec4 H_uc32 = H_uc31 + min(H_uc31, uv4);
	vec4 H_wf_c33 = H_uc32 + max(H_uc32, uv4);
	vec4 H_itgwo_c34 = H_wf_c33 + clamp(H_wf_c33, uv4, uv4);
	vec4 H_h_c35 = H_itgwo_c34 + mix(H_itgwo_c34, H_itgwo_c34, H_itgwo_c34);
	vec4 H_lfzxvv_c36 = H_h_c35 + step(H_h_c35, H_h_c35);
	vec4 H_f_c37 = H_lfzxvv_c36 + smoothstep(H_lfzxvv_c36, H_lfzxvv_c36, H_lfzxvv_c36);
	vec4 H_uc38 = H_f_c37 + step(uf, H_f_c37);
	vec4 H_n_c39 = H_uc38 + smoothstep(uf, uf, H_uc38);
	vec4 H_u_c40 = H_n_c39 + normalize(H_n_c39);
	vec4 H_uc41 = H_u_c40 + faceforward(H_u_c40, H_u_c40, H_u_c40);
	vec4 H_ahiu_c42 = H_uc41 + reflect(H_uc41, H_uc41);
	vec4 H_wfm_c43 = H_ahiu_c42 + refract(H_ahiu_c42, H_ahiu_c42, uf);
	vec4 H_pbjqt_c44 = H_wfm_c43 + dFdx(H_wfm_c43);
	vec4 H_ig_c45 = H_pbjqt_c44 + dFdy(H_pbjqt_c44);
	vec4 H_uc46 = H_ig_c45 + fwidth(H_ig_c45);
	bool H_hwysnq_c47 = ((any(lessThan(H_uc46, uv4)) && any(lessThanEqual(H_uc46, uv4))) && any(greaterThan(H_uc46, uv4))) && any(greaterThanEqual(H_uc46, uv4));
	int H_gxb_c48 = ((((H_h_c3 + ui) * H_h_c3) - ui) / H_h_c3) % ui;
	float H_v_c49 = (((((uf + uf) * uf) - uf) / uf) + length(H_uc46)) + dot(H_uc46, H_uc46);
	float H_d_c50 = ((H_v_c49 * uf) + H_v_c49) + cross(H_uc46.xyz, H_uc46.xyz).x;
	bool H_jnz8mi1 = ((((H_hwysnq_c47 && any(equal(ub41, ub42))) && any(notEqual(ub41, ub42))) && any(ub41)) && all(ub41)) && any((not(ub41)));
	vec4 H_yzkz_c51 = vec4((((H_d_c50 == uf) || ((H_d_c50 != uf) && (H_d_c50 != C_2d0))) ? (H_d_c50 + C_1d0) : H_d_c50)) + vec4((float((~(((((((ui & ((H_gxb_c48 == C_2) ? C_0 : (H_gxb_c48 + C_1))) | C_66) ^ ui) % C_17) >> C_2) << ui))))));
	gl_FragColor = (H_jnz8mi1 ? H_uc46 : (H_uc46 + H_yzkz_c51));
	
}

