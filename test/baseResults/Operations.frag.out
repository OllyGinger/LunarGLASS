
Top IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer
@uiv4 = external addrspace(2) constant <4 x i32>
@ub = external addrspace(2) constant i1

define fastcc void @main() {
entry:
  %constructed75 = alloca <4 x float>
  %constructed = alloca <4 x float>
  %ternary = alloca <4 x float>
  %f = alloca float
  %b = alloca i1
  %i = alloca i32
  %v = alloca <4 x float>
  %0 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v1 = call <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float> %0)
  store <4 x float> %v1, <4 x float>* %v
  %1 = load <4 x float>* %v
  %2 = call <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float> %1)
  %3 = load <4 x float>* %v
  %v2 = fadd <4 x float> %3, %2
  store <4 x float> %v2, <4 x float>* %v
  %4 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %5 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i3 = mul i32 %4, %5
  store i32 %i3, i32* %i
  %6 = load <4 x float>* %v
  %7 = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %6)
  %8 = load <4 x float>* %v
  %v4 = fadd <4 x float> %8, %7
  store <4 x float> %v4, <4 x float>* %v
  %9 = load <4 x float>* %v
  %10 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %9)
  %11 = load <4 x float>* %v
  %v5 = fadd <4 x float> %11, %10
  store <4 x float> %v5, <4 x float>* %v
  %12 = load <4 x float>* %v
  %13 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %12)
  %14 = load <4 x float>* %v
  %v6 = fadd <4 x float> %14, %13
  store <4 x float> %v6, <4 x float>* %v
  %15 = load <4 x float>* %v
  %16 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %15)
  %17 = load <4 x float>* %v
  %v7 = fadd <4 x float> %17, %16
  store <4 x float> %v7, <4 x float>* %v
  %18 = load <4 x float>* %v
  %19 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %18)
  %20 = load <4 x float>* %v
  %v8 = fadd <4 x float> %20, %19
  store <4 x float> %v8, <4 x float>* %v
  %21 = load <4 x float>* %v
  %22 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %21)
  %23 = load <4 x float>* %v
  %v9 = fadd <4 x float> %23, %22
  store <4 x float> %v9, <4 x float>* %v
  %24 = load <4 x float>* %v
  %25 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %24)
  %26 = load <4 x float>* %v
  %v10 = fadd <4 x float> %26, %25
  store <4 x float> %v10, <4 x float>* %v
  %27 = load <4 x float>* %v
  %28 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %27)
  %29 = load <4 x float>* %v
  %v11 = fadd <4 x float> %29, %28
  store <4 x float> %v11, <4 x float>* %v
  %30 = load <4 x float>* %v
  %31 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %30)
  %32 = load <4 x float>* %v
  %v12 = fadd <4 x float> %32, %31
  store <4 x float> %v12, <4 x float>* %v
  %33 = load <4 x float>* %v
  %34 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %33)
  %35 = load <4 x float>* %v
  %v13 = fadd <4 x float> %35, %34
  store <4 x float> %v13, <4 x float>* %v
  %36 = load <4 x float>* %v
  %37 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %36)
  %38 = load <4 x float>* %v
  %v14 = fadd <4 x float> %38, %37
  store <4 x float> %v14, <4 x float>* %v
  %39 = load <4 x float>* %v
  %40 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %39)
  %41 = load <4 x float>* %v
  %v15 = fadd <4 x float> %41, %40
  store <4 x float> %v15, <4 x float>* %v
  %42 = load <4 x float>* %v
  %43 = load <4 x float>* %v
  %44 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %42, <4 x float> %43)
  %45 = load <4 x float>* %v
  %v16 = fadd <4 x float> %45, %44
  store <4 x float> %v16, <4 x float>* %v
  %46 = load <4 x float>* %v
  %47 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %46)
  %48 = load <4 x float>* %v
  %v17 = fadd <4 x float> %48, %47
  store <4 x float> %v17, <4 x float>* %v
  %49 = load <4 x float>* %v
  %50 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %49)
  %51 = load <4 x float>* %v
  %v18 = fadd <4 x float> %51, %50
  store <4 x float> %v18, <4 x float>* %v
  %52 = load <4 x float>* %v
  %53 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %52)
  %54 = load <4 x float>* %v
  %v19 = fadd <4 x float> %54, %53
  store <4 x float> %v19, <4 x float>* %v
  %55 = load <4 x float>* %v
  %56 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %55)
  %57 = load <4 x float>* %v
  %v20 = fadd <4 x float> %57, %56
  store <4 x float> %v20, <4 x float>* %v
  %58 = load <4 x float>* %v
  %59 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %58)
  %60 = load <4 x float>* %v
  %v21 = fadd <4 x float> %60, %59
  store <4 x float> %v21, <4 x float>* %v
  %61 = load <4 x float>* %v
  %62 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %61)
  %63 = load <4 x float>* %v
  %v22 = fadd <4 x float> %63, %62
  store <4 x float> %v22, <4 x float>* %v
  %64 = load <4 x float>* %v
  %65 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %64)
  %66 = load <4 x float>* %v
  %v23 = fadd <4 x float> %66, %65
  store <4 x float> %v23, <4 x float>* %v
  %67 = load <4 x float>* %v
  %68 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %67)
  %69 = load <4 x float>* %v
  %v24 = fadd <4 x float> %69, %68
  store <4 x float> %v24, <4 x float>* %v
  %70 = load <4 x float>* %v
  %71 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %70)
  %72 = load <4 x float>* %v
  %v25 = fadd <4 x float> %72, %71
  store <4 x float> %v25, <4 x float>* %v
  %73 = load <4 x float>* %v
  %74 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %73)
  %75 = load <4 x float>* %v
  %v26 = fadd <4 x float> %75, %74
  store <4 x float> %v26, <4 x float>* %v
  %76 = load <4 x float>* %v
  %77 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %76)
  %78 = load <4 x float>* %v
  %v27 = fadd <4 x float> %78, %77
  store <4 x float> %v27, <4 x float>* %v
  %79 = load <4 x float>* %v
  %80 = load <4 x float>* %v
  %81 = frem <4 x float> %79, %80
  %82 = load <4 x float>* %v
  %v28 = fadd <4 x float> %82, %81
  store <4 x float> %v28, <4 x float>* %v
  %83 = load <4 x float>* %v
  %84 = load <4 x float>* %v
  %85 = extractelement <4 x float> %84, i32 0
  %86 = insertelement <4 x float> undef, float %85, i32 0
  %87 = insertelement <4 x float> %86, float %85, i32 1
  %88 = insertelement <4 x float> %87, float %85, i32 2
  %89 = insertelement <4 x float> %88, float %85, i32 3
  %90 = frem <4 x float> %83, %89
  %91 = load <4 x float>* %v
  %v29 = fadd <4 x float> %91, %90
  store <4 x float> %v29, <4 x float>* %v
  %92 = load <4 x float>* %v
  %93 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %94 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %92, <4 x float> %93)
  %95 = load <4 x float>* %v
  %v30 = fadd <4 x float> %95, %94
  store <4 x float> %v30, <4 x float>* %v
  %96 = load <4 x float>* %v
  %97 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %98 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %96, <4 x float> %97)
  %99 = load <4 x float>* %v
  %v31 = fadd <4 x float> %99, %98
  store <4 x float> %v31, <4 x float>* %v
  %100 = load <4 x float>* %v
  %101 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %102 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %103 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %100, <4 x float> %101, <4 x float> %102)
  %104 = load <4 x float>* %v
  %v32 = fadd <4 x float> %104, %103
  store <4 x float> %v32, <4 x float>* %v
  %105 = load <4 x float>* %v
  %106 = load <4 x float>* %v
  %107 = load <4 x float>* %v
  %108 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %105, <4 x float> %106, <4 x float> %107)
  %109 = load <4 x float>* %v
  %v33 = fadd <4 x float> %109, %108
  store <4 x float> %v33, <4 x float>* %v
  %110 = load <4 x float>* %v
  %111 = load <4 x float>* %v
  %112 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %110, <4 x float> %111)
  %113 = load <4 x float>* %v
  %v34 = fadd <4 x float> %113, %112
  store <4 x float> %v34, <4 x float>* %v
  %114 = load <4 x float>* %v
  %115 = load <4 x float>* %v
  %116 = load <4 x float>* %v
  %117 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %114, <4 x float> %115, <4 x float> %116)
  %118 = load <4 x float>* %v
  %v35 = fadd <4 x float> %118, %117
  store <4 x float> %v35, <4 x float>* %v
  %119 = load float addrspace(2)* @uf, !gla.uniform !4
  %120 = load <4 x float>* %v
  %121 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %119, <4 x float> %120)
  %122 = load <4 x float>* %v
  %v36 = fadd <4 x float> %122, %121
  store <4 x float> %v36, <4 x float>* %v
  %123 = load float addrspace(2)* @uf, !gla.uniform !4
  %124 = load float addrspace(2)* @uf, !gla.uniform !4
  %125 = load <4 x float>* %v
  %126 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %123, float %124, <4 x float> %125)
  %127 = load <4 x float>* %v
  %v37 = fadd <4 x float> %127, %126
  store <4 x float> %v37, <4 x float>* %v
  %128 = load <4 x float>* %v
  %129 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %128)
  %130 = load <4 x float>* %v
  %v38 = fadd <4 x float> %130, %129
  store <4 x float> %v38, <4 x float>* %v
  %131 = load <4 x float>* %v
  %132 = load <4 x float>* %v
  %133 = load <4 x float>* %v
  %134 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %131, <4 x float> %132, <4 x float> %133)
  %135 = load <4 x float>* %v
  %v39 = fadd <4 x float> %135, %134
  store <4 x float> %v39, <4 x float>* %v
  %136 = load <4 x float>* %v
  %137 = load <4 x float>* %v
  %138 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %136, <4 x float> %137)
  %139 = load <4 x float>* %v
  %v40 = fadd <4 x float> %139, %138
  store <4 x float> %v40, <4 x float>* %v
  %140 = load <4 x float>* %v
  %141 = load <4 x float>* %v
  %142 = load float addrspace(2)* @uf, !gla.uniform !4
  %143 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %140, <4 x float> %141, float %142)
  %144 = load <4 x float>* %v
  %v41 = fadd <4 x float> %144, %143
  store <4 x float> %v41, <4 x float>* %v
  %145 = load <4 x float>* %v
  %146 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %145)
  %147 = load <4 x float>* %v
  %v42 = fadd <4 x float> %147, %146
  store <4 x float> %v42, <4 x float>* %v
  %148 = load <4 x float>* %v
  %149 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %148)
  %150 = load <4 x float>* %v
  %v43 = fadd <4 x float> %150, %149
  store <4 x float> %v43, <4 x float>* %v
  %151 = load <4 x float>* %v
  %152 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %151)
  %153 = load <4 x float>* %v
  %v44 = fadd <4 x float> %153, %152
  store <4 x float> %v44, <4 x float>* %v
  %154 = load <4 x float>* %v
  %155 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %156 = fcmp olt <4 x float> %154, %155
  %b45 = call i1 @llvm.gla.any.v4i1(<4 x i1> %156)
  store i1 %b45, i1* %b
  %157 = load i1* %b
  %158 = load <4 x float>* %v
  %159 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %160 = fcmp ole <4 x float> %158, %159
  %161 = call i1 @llvm.gla.any.v4i1(<4 x i1> %160)
  %b46 = and i1 %157, %161
  store i1 %b46, i1* %b
  %162 = load i1* %b
  %163 = load <4 x float>* %v
  %164 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %165 = fcmp ogt <4 x float> %163, %164
  %166 = call i1 @llvm.gla.any.v4i1(<4 x i1> %165)
  %b47 = and i1 %162, %166
  store i1 %b47, i1* %b
  %167 = load i1* %b
  %168 = load <4 x float>* %v
  %169 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %170 = fcmp oge <4 x float> %168, %169
  %171 = call i1 @llvm.gla.any.v4i1(<4 x i1> %170)
  %b48 = and i1 %167, %171
  store i1 %b48, i1* %b
  %172 = load i1* %b
  %173 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %174 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %175 = icmp eq <4 x i1> %173, %174
  %176 = call i1 @llvm.gla.any.v4i1(<4 x i1> %175)
  %b49 = and i1 %172, %176
  store i1 %b49, i1* %b
  %177 = load i1* %b
  %178 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %179 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %180 = icmp ne <4 x i1> %178, %179
  %181 = call i1 @llvm.gla.any.v4i1(<4 x i1> %180)
  %b50 = and i1 %177, %181
  store i1 %b50, i1* %b
  %182 = load i1* %b
  %183 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %184 = call i1 @llvm.gla.any.v4i1(<4 x i1> %183)
  %b51 = and i1 %182, %184
  store i1 %b51, i1* %b
  %185 = load i1* %b
  %186 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %187 = call i1 @llvm.gla.all.v4i1(<4 x i1> %186)
  %b52 = and i1 %185, %187
  store i1 %b52, i1* %b
  %188 = load i1* %b
  %189 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %190 = xor <4 x i1> %189, <i1 true, i1 true, i1 true, i1 true>
  %191 = call i1 @llvm.gla.any.v4i1(<4 x i1> %190)
  %b53 = and i1 %188, %191
  store i1 %b53, i1* %b
  %192 = load i32* %i
  %193 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %194 = add i32 %192, %193
  %195 = load i32* %i
  %196 = mul i32 %194, %195
  %197 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %198 = sub i32 %196, %197
  %199 = load i32* %i
  %i54 = sdiv i32 %198, %199
  store i32 %i54, i32* %i
  %200 = load i32* %i
  %201 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i55 = srem i32 %200, %201
  store i32 %i55, i32* %i
  %202 = load i32* %i
  %203 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %204 = icmp eq i32 %202, %203
  %205 = load i32* %i
  %206 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %207 = icmp ne i32 %205, %206
  %208 = load i32* %i
  %209 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %210 = icmp eq i32 %208, %209
  %211 = and i1 %207, %210
  %212 = load i32* %i
  %213 = icmp ne i32 %212, 2
  %214 = xor i1 %211, %213
  %215 = or i1 %204, %214
  br i1 %215, label %then, label %ifmerge

then:                                             ; preds = %entry
  %216 = load i32* %i
  %i56 = add i32 %216, 1
  store i32 %i56, i32* %i
  br label %ifmerge

ifmerge:                                          ; preds = %entry, %then
  %217 = load float addrspace(2)* @uf, !gla.uniform !4
  %218 = load float addrspace(2)* @uf, !gla.uniform !4
  %219 = fadd float %217, %218
  %220 = load float addrspace(2)* @uf, !gla.uniform !4
  %221 = fmul float %219, %220
  %222 = load float addrspace(2)* @uf, !gla.uniform !4
  %223 = fsub float %221, %222
  %224 = load float addrspace(2)* @uf, !gla.uniform !4
  %f57 = fdiv float %223, %224
  store float %f57, float* %f
  %225 = load <4 x float>* %v
  %226 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %225)
  %227 = load float* %f
  %f58 = fadd float %227, %226
  store float %f58, float* %f
  %228 = load <4 x float>* %v
  %229 = load <4 x float>* %v
  %230 = call float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float> %228, <4 x float> %229)
  %231 = load float* %f
  %f59 = fadd float %231, %230
  store float %f59, float* %f
  %232 = load <4 x float>* %v
  %233 = load <4 x float>* %v
  %234 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %232, <4 x float> %233)
  %235 = load float* %f
  %f60 = fadd float %235, %234
  store float %f60, float* %f
  %236 = load float* %f
  %237 = load float addrspace(2)* @uf, !gla.uniform !4
  %238 = fmul float %236, %237
  %239 = load float* %f
  %f61 = fadd float %239, %238
  store float %f61, float* %f
  %240 = load <4 x float>* %v
  %241 = extractelement <4 x float> %240, i32 0
  %242 = insertelement <3 x float> undef, float %241, i32 0
  %243 = extractelement <4 x float> %240, i32 1
  %244 = insertelement <3 x float> %242, float %243, i32 1
  %245 = extractelement <4 x float> %240, i32 2
  %246 = insertelement <3 x float> %244, float %245, i32 2
  %247 = load <4 x float>* %v
  %248 = extractelement <4 x float> %247, i32 0
  %249 = insertelement <3 x float> undef, float %248, i32 0
  %250 = extractelement <4 x float> %247, i32 1
  %251 = insertelement <3 x float> %249, float %250, i32 1
  %252 = extractelement <4 x float> %247, i32 2
  %253 = insertelement <3 x float> %251, float %252, i32 2
  %254 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %246, <3 x float> %253)
  %255 = extractelement <3 x float> %254, i32 0
  %256 = load float* %f
  %f62 = fadd float %256, %255
  store float %f62, float* %f
  %257 = load float* %f
  %258 = load float addrspace(2)* @uf, !gla.uniform !4
  %259 = fcmp oeq float %257, %258
  %260 = load float* %f
  %261 = load float addrspace(2)* @uf, !gla.uniform !4
  %262 = fcmp one float %260, %261
  %263 = load float* %f
  %264 = fcmp one float %263, 2.000000e+00
  %265 = and i1 %262, %264
  %266 = or i1 %259, %265
  br i1 %266, label %then63, label %ifmerge65

then63:                                           ; preds = %ifmerge
  %267 = load float* %f
  %f64 = fadd float %267, 1.000000e+00
  store float %f64, float* %f
  br label %ifmerge65

ifmerge65:                                        ; preds = %ifmerge, %then63
  %268 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %269 = load i32* %i
  %i66 = and i32 %269, %268
  store i32 %i66, i32* %i
  %270 = load i32* %i
  %i67 = or i32 %270, 66
  store i32 %i67, i32* %i
  %271 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %272 = load i32* %i
  %i68 = xor i32 %272, %271
  store i32 %i68, i32* %i
  %273 = load i32* %i
  %i69 = srem i32 %273, 17
  store i32 %i69, i32* %i
  %274 = load i32* %i
  %i70 = ashr i32 %274, 2
  store i32 %i70, i32* %i
  %275 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %276 = load i32* %i
  %i71 = shl i32 %276, %275
  store i32 %i71, i32* %i
  %277 = load i32* %i
  %i72 = xor i32 %277, -1
  store i32 %i72, i32* %i
  %278 = load i1* %b
  %b73 = xor i1 %278, true
  store i1 %b73, i1* %b
  %279 = load i1* %b
  br i1 %279, label %then74, label %else

then74:                                           ; preds = %ifmerge65
  %280 = load i32* %i
  %281 = sitofp i32 %280 to float
  %282 = load <4 x float>* %constructed
  %283 = insertelement <4 x float> undef, float %281, i32 0
  %284 = insertelement <4 x float> %283, float %281, i32 1
  %285 = insertelement <4 x float> %284, float %281, i32 2
  %286 = insertelement <4 x float> %285, float %281, i32 3
  %287 = load float* %f
  %288 = load <4 x float>* %constructed75
  %289 = insertelement <4 x float> undef, float %287, i32 0
  %290 = insertelement <4 x float> %289, float %287, i32 1
  %291 = insertelement <4 x float> %290, float %287, i32 2
  %292 = insertelement <4 x float> %291, float %287, i32 3
  %293 = fadd <4 x float> %286, %292
  %294 = load <4 x float>* %v
  %ternary76 = fadd <4 x float> %293, %294
  store <4 x float> %ternary76, <4 x float>* %ternary
  br label %ifmerge78

else:                                             ; preds = %ifmerge65
  %ternary77 = load <4 x float>* %v
  store <4 x float> %ternary77, <4 x float>* %ternary
  br label %ifmerge78

ifmerge78:                                        ; preds = %else, %then74
  %gl_FragColor = load <4 x float>* %ternary
  store <4 x float> %gl_FragColor, <4 x float>* @gl_FragColor
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %ifmerge78
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}


Bottom IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer

define fastcc void @main() {
entry:
  %0 = load <4 x float> addrspace(2)* @uv4, align 16, !gla.uniform !1
  %1 = fmul <4 x float> %0, <float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000>
  %2 = fmul <4 x float> %1, <float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000>
  %v2 = fadd <4 x float> %1, %2
  %3 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i3 = mul i32 %3, %3
  %4 = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %v2)
  %v4 = fadd <4 x float> %4, %v2
  %5 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %v4)
  %v5 = fadd <4 x float> %5, %v4
  %6 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %v5)
  %v6 = fadd <4 x float> %6, %v5
  %7 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %v6)
  %v7 = fadd <4 x float> %7, %v6
  %8 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %v7)
  %v8 = fadd <4 x float> %8, %v7
  %9 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %v8)
  %v9 = fadd <4 x float> %9, %v8
  %10 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %v9)
  %v10 = fadd <4 x float> %10, %v9
  %11 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %v10)
  %v11 = fadd <4 x float> %11, %v10
  %12 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %v11)
  %v12 = fadd <4 x float> %12, %v11
  %13 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %v12)
  %v13 = fadd <4 x float> %13, %v12
  %14 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %v13)
  %v14 = fadd <4 x float> %14, %v13
  %15 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %v14)
  %v15 = fadd <4 x float> %15, %v14
  %16 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %v15, <4 x float> %v15)
  %v16 = fadd <4 x float> %16, %v15
  %17 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %v16)
  %v17 = fadd <4 x float> %17, %v16
  %18 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %v17)
  %v18 = fadd <4 x float> %18, %v17
  %19 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %v18)
  %v19 = fadd <4 x float> %19, %v18
  %20 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %v19)
  %v20 = fadd <4 x float> %20, %v19
  %21 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %v20)
  %v21 = fadd <4 x float> %21, %v20
  %22 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %v21)
  %v22 = fadd <4 x float> %22, %v21
  %23 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %v22)
  %v23 = fadd <4 x float> %23, %v22
  %24 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %v23)
  %v24 = fadd <4 x float> %24, %v23
  %25 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %v24)
  %v25 = fadd <4 x float> %25, %v24
  %26 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %v25)
  %v26 = fadd <4 x float> %26, %v25
  %27 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %v26)
  %v27 = fadd <4 x float> %27, %v26
  %28 = frem <4 x float> %v27, %v27
  %v28 = fadd <4 x float> %28, %v27
  %29 = call <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float> %v28, <4 x i32> zeroinitializer)
  %30 = frem <4 x float> %v28, %29
  %v29 = fadd <4 x float> %30, %v28
  %31 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %v29, <4 x float> %0)
  %v30 = fadd <4 x float> %31, %v29
  %32 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %v30, <4 x float> %0)
  %v31 = fadd <4 x float> %32, %v30
  %33 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %v31, <4 x float> %0, <4 x float> %0)
  %v32 = fadd <4 x float> %33, %v31
  %34 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %v32, <4 x float> %v32, <4 x float> %v32)
  %v33 = fadd <4 x float> %34, %v32
  %35 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %v33, <4 x float> %v33)
  %v34 = fadd <4 x float> %35, %v33
  %36 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %v34, <4 x float> %v34, <4 x float> %v34)
  %v35 = fadd <4 x float> %36, %v34
  %37 = load float addrspace(2)* @uf, align 4, !gla.uniform !4
  %38 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %37, <4 x float> %v35)
  %v36 = fadd <4 x float> %v35, %38
  %39 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %37, float %37, <4 x float> %v36)
  %v37 = fadd <4 x float> %v36, %39
  %40 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %v37)
  %v38 = fadd <4 x float> %v37, %40
  %41 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %v38, <4 x float> %v38, <4 x float> %v38)
  %v39 = fadd <4 x float> %v38, %41
  %42 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %v39, <4 x float> %v39)
  %v40 = fadd <4 x float> %v39, %42
  %43 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %v40, <4 x float> %v40, float %37)
  %v41 = fadd <4 x float> %v40, %43
  %44 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %v41)
  %v42 = fadd <4 x float> %v41, %44
  %45 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %v42)
  %v43 = fadd <4 x float> %v42, %45
  %46 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %v43)
  %v44 = fadd <4 x float> %v43, %46
  %47 = call <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float> %v44, <3 x i32> <i32 0, i32 1, i32 2>)
  %48 = fcmp olt <4 x float> %v44, %0
  %b45 = call i1 @llvm.gla.any.v4i1(<4 x i1> %48)
  %49 = fcmp ole <4 x float> %v44, %0
  %50 = call i1 @llvm.gla.any.v4i1(<4 x i1> %49)
  %b46 = and i1 %b45, %50
  %51 = fcmp ogt <4 x float> %v44, %0
  %52 = call i1 @llvm.gla.any.v4i1(<4 x i1> %51)
  %b47 = and i1 %b46, %52
  %53 = fcmp oge <4 x float> %v44, %0
  %54 = call i1 @llvm.gla.any.v4i1(<4 x i1> %53)
  %b48 = and i1 %b47, %54
  %55 = load <4 x i1> addrspace(2)* @ub41, align 4, !gla.uniform !5
  %56 = load <4 x i1> addrspace(2)* @ub42, align 4, !gla.uniform !6
  %57 = icmp eq <4 x i1> %55, %56
  %58 = call i1 @llvm.gla.any.v4i1(<4 x i1> %57)
  %b49 = and i1 %b48, %58
  %59 = icmp ne <4 x i1> %55, %56
  %60 = call i1 @llvm.gla.any.v4i1(<4 x i1> %59)
  %b50 = and i1 %b49, %60
  %61 = call i1 @llvm.gla.any.v4i1(<4 x i1> %55)
  %b51 = and i1 %b50, %61
  %62 = call i1 @llvm.gla.all.v4i1(<4 x i1> %55)
  %b52 = and i1 %b51, %62
  %63 = xor <4 x i1> %55, <i1 true, i1 true, i1 true, i1 true>
  %64 = call i1 @llvm.gla.any.v4i1(<4 x i1> %63)
  %b53 = and i1 %b52, %64
  %65 = add i32 %i3, %3
  %66 = mul i32 %65, %i3
  %67 = sub i32 %66, %3
  %i54 = sdiv i32 %67, %i3
  %i55 = srem i32 %i54, %3
  %68 = fadd float %37, %37
  %69 = fmul float %37, %68
  %70 = fsub float %69, %37
  %f57 = fdiv float %70, %37
  %71 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %v44)
  %f58 = fadd float %f57, %71
  %72 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %v44, <4 x float> %v44)
  %f60 = fadd float %f58, %72
  %73 = fmul float %37, %f60
  %f61 = fadd float %f60, %73
  %74 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %47, <3 x float> %47)
  %75 = extractelement <3 x float> %74, i32 0
  %f62 = fadd float %75, %f61
  %76 = fcmp oeq float %f62, %37
  %77 = fcmp one float %f62, %37
  %78 = fcmp one float %f62, 2.000000e+00
  %79 = and i1 %77, %78
  %80 = or i1 %76, %79
  %f64 = fadd float %f62, 1.000000e+00
  %select = select i1 %80, float %f64, float %f62
  %81 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %select, <4 x i32> zeroinitializer)
  %82 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i56 = add i32 %i55, 1
  %83 = icmp eq i32 %i55, 2
  %.i56 = select i1 %83, i32 0, i32 %i56
  %i66 = and i32 %82, %.i56
  %i67 = or i32 %i66, 66
  %i68 = xor i32 %i67, %82
  %i69 = srem i32 %i68, 17
  %i70 = ashr i32 %i69, 2
  %i71 = shl i32 %i70, %82
  %i72 = xor i32 %i71, -1
  %84 = sitofp i32 %i72 to float
  %85 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %84, <4 x i32> zeroinitializer)
  %86 = fadd <4 x float> %81, %85
  %ternary76 = fadd <4 x float> %v44, %86
  %select79 = select i1 %b53, <4 x float> %v44, <4 x float> %ternary76
  store <4 x float> %select79, <4 x float>* @gl_FragColor, align 16
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %entry
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float>, <4 x i32>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float>, <3 x i32>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float, <4 x i32>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}
#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 L_1 = vec4(0.0174533);
const vec4 L_3 = vec4(57.2958);
const float L_69 = 2.0;
const float L_6a = 1.0;
const int L_6c = 1;
const int L_6d = 2;
const int L_6e = 0;
const int L_6f = 66;
const int L_70 = 17;

void main()
{
	vec4 L_2 = uv4 * L_1;
	vec4 L_4 = (L_2 * L_3) + L_2;
	int L_5 = ui * ui;
	vec4 L_6 = sin(L_4);
	vec4 L_7 = L_4 + L_6;
	vec4 L_8 = cos(L_7);
	vec4 L_9 = L_7 + L_8;
	vec4 L_a = tan(L_9);
	vec4 L_b = L_9 + L_a;
	vec4 L_c = asin(L_b);
	vec4 L_d = L_b + L_c;
	vec4 L_e = acos(L_d);
	vec4 L_f = L_d + L_e;
	vec4 L_10 = atan(L_f);
	vec4 L_11 = L_10 + L_f;
	vec4 L_12 = sinh(L_11);
	vec4 L_13 = L_11 + L_12;
	vec4 L_14 = cosh(L_13);
	vec4 L_15 = L_13 + L_14;
	vec4 L_16 = tanh(L_15);
	vec4 L_17 = L_15 + L_16;
	vec4 L_18 = asinh(L_17);
	vec4 L_19 = L_17 + L_18;
	vec4 L_1a = acosh(L_19);
	vec4 L_1b = L_19 + L_1a;
	vec4 L_1c = atanh(L_1b);
	vec4 L_1d = L_1b + L_1c;
	vec4 L_1e = pow(L_1d, L_1d);
	vec4 L_1f = L_1d + L_1e;
	vec4 L_20 = exp(L_1f);
	vec4 L_21 = L_1f + L_20;
	vec4 L_22 = log(L_21);
	vec4 L_23 = L_21 + L_22;
	vec4 L_24 = exp2(L_23);
	vec4 L_25 = L_23 + L_24;
	vec4 L_26 = log2(L_25);
	vec4 L_27 = L_25 + L_26;
	vec4 L_28 = sqrt(L_27);
	vec4 L_29 = L_27 + L_28;
	vec4 L_2a = inversesqrt(L_29);
	vec4 L_2b = L_29 + L_2a;
	vec4 L_2c = abs(L_2b);
	vec4 L_2d = L_2b + L_2c;
	vec4 L_2e = sign(L_2d);
	vec4 L_2f = L_2d + L_2e;
	vec4 L_30 = floor(L_2f);
	vec4 L_31 = L_2f + L_30;
	vec4 L_32 = ceil(L_31);
	vec4 L_33 = L_31 + L_32;
	vec4 L_34 = fract(L_33);
	vec4 L_35 = L_33 + L_34;
	vec4 L_36 = mod(L_35, L_35);
	vec4 L_37 = L_35 + L_36;
	vec4 L_38 = L_37.xxxx;
	vec4 L_39 = mod(L_37, L_38);
	vec4 L_3a = L_37 + L_39;
	vec4 L_3b = min(L_3a, uv4);
	vec4 L_3c = L_3a + L_3b;
	vec4 L_3d = max(L_3c, uv4);
	vec4 L_3e = L_3c + L_3d;
	vec4 L_3f = clamp(L_3e, uv4, uv4);
	vec4 L_40 = L_3e + L_3f;
	vec4 L_41 = mix(L_40, L_40, L_40);
	vec4 L_42 = L_40 + L_41;
	vec4 L_43 = step(L_42, L_42);
	vec4 L_44 = L_42 + L_43;
	vec4 L_45 = smoothstep(L_44, L_44, L_44);
	vec4 L_46 = L_44 + L_45;
	vec4 L_47 = step(uf, L_46);
	vec4 L_48 = L_46 + L_47;
	vec4 L_49 = smoothstep(uf, uf, L_48);
	vec4 L_4a = L_48 + L_49;
	vec4 L_4b = normalize(L_4a);
	vec4 L_4c = L_4a + L_4b;
	vec4 L_4d = faceforward(L_4c, L_4c, L_4c);
	vec4 L_4e = L_4c + L_4d;
	vec4 L_4f = reflect(L_4e, L_4e);
	vec4 L_50 = L_4e + L_4f;
	vec4 L_51 = refract(L_50, L_50, uf);
	vec4 L_52 = L_50 + L_51;
	vec4 L_53 = dFdx(L_52);
	vec4 L_54 = L_52 + L_53;
	vec4 L_55 = dFdy(L_54);
	vec4 L_56 = L_54 + L_55;
	vec4 L_57 = fwidth(L_56);
	vec4 L_58 = L_56 + L_57;
	vec3 L_59 = vec3(L_58);
	bool L_5a = any((lessThan(L_58, uv4)));
	bool L_5b = any((lessThanEqual(L_58, uv4)));
	bool L_5c = any((greaterThan(L_58, uv4)));
	bool L_5d = any((greaterThanEqual(L_58, uv4)));
	bool L_5e = any((equal(ub41, ub42)));
	bool L_5f = any((notEqual(ub41, ub42)));
	bool L_60 = any(ub41);
	bool L_61 = all(ub41);
	bool L_62 = any((not(ub41)));
	int L_63 = ((((L_5 + ui) * L_5) - ui) / L_5) % ui;
	float L_64 = length(L_58);
	float L_65 = dot(L_58, L_58);
	float L_66 = (((((uf + uf) * uf) - uf) / uf) + L_64) + L_65;
	vec3 L_67 = cross(L_59, L_59);
	float L_68 = ((L_66 * uf) + L_66) + L_67.x;
	vec4 L_6b = vec4((((L_68 == uf) || ((L_68 != uf) && (L_68 != L_69))) ? (L_68 + L_6a) : L_68));
	vec4 L_71 = vec4((float((~(((((((ui & ((L_63 == L_6d) ? L_6e : (L_63 + L_6c))) | L_6f) ^ ui) % L_70) >> L_6d) << ui))))));
	gl_FragColor = (((((((((L_5a && L_5b) && L_5c) && L_5d) && L_5e) && L_5f) && L_60) && L_61) && L_62) ? L_58 : ((L_6b + L_71) + L_58));
	
}

#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 L_1 = vec4(0.0174533);
const vec4 L_3 = vec4(57.2958);
const float L_69 = 2.0;
const float L_6a = 1.0;
const int L_6c = 2;
const int L_6d = 1;
const int L_6e = 0;
const int L_6f = 66;
const int L_70 = 17;

void main()
{
	vec4 L_uc1 = uv4 * L_1;
	vec4 L_uc2 = (L_uc1 * L_3) + L_uc1;
	int L_uc3 = ui * ui;
	vec4 L_uc4 = sin(L_uc2);
	vec4 L_uc5 = L_uc2 + L_uc4;
	vec4 L_uc6 = cos(L_uc5);
	vec4 L_uc7 = L_uc5 + L_uc6;
	vec4 L_a_c8 = tan(L_uc7);
	vec4 L_b_c9 = L_a_c8 + L_uc7;
	vec4 L_c10 = asin(L_b_c9);
	vec4 L_d_c11 = L_b_c9 + L_c10;
	vec4 L_e_c12 = acos(L_d_c11);
	vec4 L_f_c13 = L_d_c11 + L_e_c12;
	vec4 L_uc14 = atan(L_f_c13);
	vec4 L_uc15 = L_f_c13 + L_uc14;
	vec4 L_uc16 = sinh(L_uc15);
	vec4 L_uc17 = L_uc15 + L_uc16;
	vec4 L_uc18 = cosh(L_uc17);
	vec4 L_uc19 = L_uc17 + L_uc18;
	vec4 L_uc20 = tanh(L_uc19);
	vec4 L_uc21 = L_uc19 + L_uc20;
	vec4 L_uc22 = asinh(L_uc21);
	vec4 L_uc23 = L_uc21 + L_uc22;
	vec4 L_uc24 = acosh(L_uc23);
	vec4 L_uc25 = L_uc23 + L_uc24;
	vec4 L_uc26 = atanh(L_uc25);
	vec4 L_uc27 = L_uc25 + L_uc26;
	vec4 L_uc28 = pow(L_uc27, L_uc27);
	vec4 L_uc29 = L_uc27 + L_uc28;
	vec4 L_uc30 = exp(L_uc29);
	vec4 L_uc31 = L_uc29 + L_uc30;
	vec4 L_uc32 = log(L_uc31);
	vec4 L_uc33 = L_uc31 + L_uc32;
	vec4 L_uc34 = exp2(L_uc33);
	vec4 L_uc35 = L_uc33 + L_uc34;
	vec4 L_uc36 = log2(L_uc35);
	vec4 L_uc37 = L_uc35 + L_uc36;
	vec4 L_uc38 = sqrt(L_uc37);
	vec4 L_uc39 = L_uc37 + L_uc38;
	vec4 L_uc40 = inversesqrt(L_uc39);
	vec4 L_uc41 = L_uc39 + L_uc40;
	vec4 L_uc42 = abs(L_uc41);
	vec4 L_uc43 = L_uc41 + L_uc42;
	vec4 L_uc44 = sign(L_uc43);
	vec4 L_uc45 = L_uc43 + L_uc44;
	vec4 L_uc46 = floor(L_uc45);
	vec4 L_uc47 = L_uc45 + L_uc46;
	vec4 L_uc48 = ceil(L_uc47);
	vec4 L_uc49 = L_uc47 + L_uc48;
	vec4 L_uc50 = fract(L_uc49);
	vec4 L_uc51 = L_uc49 + L_uc50;
	vec4 L_uc52 = mod(L_uc51, L_uc51);
	vec4 L_uc53 = L_uc51 + L_uc52;
	vec4 L_38 = L_uc53.xxxx;
	vec4 L_uc54 = mod(L_uc53, L_38);
	vec4 L_uc55 = L_uc53 + L_uc54;
	vec4 L_uc56 = min(L_uc55, uv4);
	vec4 L_uc57 = L_uc55 + L_uc56;
	vec4 L_uc58 = max(L_uc57, uv4);
	vec4 L_uc59 = L_uc57 + L_uc58;
	vec4 L_uc60 = clamp(L_uc59, uv4, uv4);
	vec4 L_uc61 = L_uc59 + L_uc60;
	vec4 L_uc62 = mix(L_uc61, L_uc61, L_uc61);
	vec4 L_uc63 = L_uc61 + L_uc62;
	vec4 L_uc64 = step(L_uc63, L_uc63);
	vec4 L_uc65 = L_uc63 + L_uc64;
	vec4 L_uc66 = smoothstep(L_uc65, L_uc65, L_uc65);
	vec4 L_uc67 = L_uc65 + L_uc66;
	vec4 L_uc68 = step(uf, L_uc67);
	vec4 L_uc69 = L_uc67 + L_uc68;
	vec4 L_uc70 = smoothstep(uf, uf, L_uc69);
	vec4 L_uc71 = L_uc69 + L_uc70;
	vec4 L_uc72 = normalize(L_uc71);
	vec4 L_uc73 = L_uc71 + L_uc72;
	vec4 L_uc74 = faceforward(L_uc73, L_uc73, L_uc73);
	vec4 L_uc75 = L_uc73 + L_uc74;
	vec4 L_uc76 = reflect(L_uc75, L_uc75);
	vec4 L_uc77 = L_uc75 + L_uc76;
	vec4 L_uc78 = refract(L_uc77, L_uc77, uf);
	vec4 L_uc79 = L_uc77 + L_uc78;
	vec4 L_uc80 = dFdx(L_uc79);
	vec4 L_uc81 = L_uc79 + L_uc80;
	vec4 L_uc82 = dFdy(L_uc81);
	vec4 L_uc83 = L_uc81 + L_uc82;
	vec4 L_uc84 = fwidth(L_uc83);
	vec4 L_uc85 = L_uc83 + L_uc84;
	vec3 L_59 = vec3(L_uc85);
	bool L_uc86 = any((lessThan(L_uc85, uv4)));
	bool L_uc87 = any((lessThanEqual(L_uc85, uv4)));
	bool L_uc88 = any((greaterThan(L_uc85, uv4)));
	bool L_uc89 = any((greaterThanEqual(L_uc85, uv4)));
	bool L_uc90 = any((equal(ub41, ub42)));
	bool L_uc91 = any((notEqual(ub41, ub42)));
	bool L_uc92 = any(ub41);
	bool L_uc93 = all(ub41);
	bool L_uc94 = any((not(ub41)));
	int L_uc95 = ((((L_uc3 + ui) * L_uc3) - ui) / L_uc3) % ui;
	float L_uc96 = length(L_uc85);
	float L_uc97 = dot(L_uc85, L_uc85);
	float L_uc98 = (((((uf + uf) * uf) - uf) / uf) + L_uc96) + L_uc97;
	vec3 L_uc99 = cross(L_59, L_59);
	float L_uc100 = ((L_uc98 * uf) + L_uc98) + L_uc99.x;
	vec4 L_6b = vec4((((L_uc100 == uf) || ((L_uc100 != uf) && (L_uc100 != L_69))) ? (L_uc100 + L_6a) : L_uc100));
	vec4 L_71 = vec4((float((~(((((((ui & ((L_uc95 == L_6c) ? L_6e : (L_uc95 + L_6d))) | L_6f) ^ ui) % L_70) >> L_6c) << ui))))));
	vec4 select_c101 = ((((((((L_uc86 && L_uc87) && L_uc88) && L_uc89) && L_uc90) && L_uc91) && L_uc92) && L_uc93) && L_uc94) ? L_uc85 : ((L_6b + L_71) + L_uc85);
	gl_FragColor = select_c101;
	
}

