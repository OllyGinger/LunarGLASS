
Top IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer
@uiv4 = external addrspace(2) constant <4 x i32>
@ub = external addrspace(2) constant i1

define fastcc void @main() {
entry:
  %gl_FragColor129 = alloca <4 x float>
  %gl_FragColor128 = alloca <4 x float>
  %gl_FragColor = alloca <4 x float>
  %f = alloca float
  %b = alloca i1
  %i = alloca i32
  %v = alloca <4 x float>
  %0 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v2 = call <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float> %0)
  store <4 x float> %v2, <4 x float>* %v
  %1 = load <4 x float>* %v
  %v3 = call <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float> %1)
  %2 = load <4 x float>* %v
  %v4 = fadd <4 x float> %2, %v3
  store <4 x float> %v4, <4 x float>* %v
  %3 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %4 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i5 = mul i32 %3, %4
  store i32 %i5, i32* %i
  %5 = load <4 x float>* %v
  %uni = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %5)
  %6 = load <4 x float>* %v
  %v6 = fadd <4 x float> %6, %uni
  store <4 x float> %v6, <4 x float>* %v
  %7 = load <4 x float>* %v
  %v7 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %7)
  %8 = load <4 x float>* %v
  %v8 = fadd <4 x float> %8, %v7
  store <4 x float> %v8, <4 x float>* %v
  %9 = load <4 x float>* %v
  %v9 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %9)
  %10 = load <4 x float>* %v
  %v10 = fadd <4 x float> %10, %v9
  store <4 x float> %v10, <4 x float>* %v
  %11 = load <4 x float>* %v
  %v11 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %11)
  %12 = load <4 x float>* %v
  %v12 = fadd <4 x float> %12, %v11
  store <4 x float> %v12, <4 x float>* %v
  %13 = load <4 x float>* %v
  %v13 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %13)
  %14 = load <4 x float>* %v
  %v14 = fadd <4 x float> %14, %v13
  store <4 x float> %v14, <4 x float>* %v
  %15 = load <4 x float>* %v
  %v15 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %15)
  %16 = load <4 x float>* %v
  %v16 = fadd <4 x float> %16, %v15
  store <4 x float> %v16, <4 x float>* %v
  %17 = load <4 x float>* %v
  %v17 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %17)
  %18 = load <4 x float>* %v
  %v18 = fadd <4 x float> %18, %v17
  store <4 x float> %v18, <4 x float>* %v
  %19 = load <4 x float>* %v
  %v19 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %19)
  %20 = load <4 x float>* %v
  %v20 = fadd <4 x float> %20, %v19
  store <4 x float> %v20, <4 x float>* %v
  %21 = load <4 x float>* %v
  %v21 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %21)
  %22 = load <4 x float>* %v
  %v22 = fadd <4 x float> %22, %v21
  store <4 x float> %v22, <4 x float>* %v
  %23 = load <4 x float>* %v
  %v23 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %23)
  %24 = load <4 x float>* %v
  %v24 = fadd <4 x float> %24, %v23
  store <4 x float> %v24, <4 x float>* %v
  %25 = load <4 x float>* %v
  %v25 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %25)
  %26 = load <4 x float>* %v
  %v26 = fadd <4 x float> %26, %v25
  store <4 x float> %v26, <4 x float>* %v
  %27 = load <4 x float>* %v
  %v27 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %27)
  %28 = load <4 x float>* %v
  %v28 = fadd <4 x float> %28, %v27
  store <4 x float> %v28, <4 x float>* %v
  %29 = load <4 x float>* %v
  %30 = load <4 x float>* %v
  %v29 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %29, <4 x float> %30)
  %31 = load <4 x float>* %v
  %v30 = fadd <4 x float> %31, %v29
  store <4 x float> %v30, <4 x float>* %v
  %32 = load <4 x float>* %v
  %v31 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %32)
  %33 = load <4 x float>* %v
  %v32 = fadd <4 x float> %33, %v31
  store <4 x float> %v32, <4 x float>* %v
  %34 = load <4 x float>* %v
  %v33 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %34)
  %35 = load <4 x float>* %v
  %v34 = fadd <4 x float> %35, %v33
  store <4 x float> %v34, <4 x float>* %v
  %36 = load <4 x float>* %v
  %v35 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %36)
  %37 = load <4 x float>* %v
  %v36 = fadd <4 x float> %37, %v35
  store <4 x float> %v36, <4 x float>* %v
  %38 = load <4 x float>* %v
  %v37 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %38)
  %39 = load <4 x float>* %v
  %v38 = fadd <4 x float> %39, %v37
  store <4 x float> %v38, <4 x float>* %v
  %40 = load <4 x float>* %v
  %v39 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %40)
  %41 = load <4 x float>* %v
  %v40 = fadd <4 x float> %41, %v39
  store <4 x float> %v40, <4 x float>* %v
  %42 = load <4 x float>* %v
  %v41 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %42)
  %43 = load <4 x float>* %v
  %v42 = fadd <4 x float> %43, %v41
  store <4 x float> %v42, <4 x float>* %v
  %44 = load <4 x float>* %v
  %v43 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %44)
  %45 = load <4 x float>* %v
  %v44 = fadd <4 x float> %45, %v43
  store <4 x float> %v44, <4 x float>* %v
  %46 = load <4 x float>* %v
  %v45 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %46)
  %47 = load <4 x float>* %v
  %v46 = fadd <4 x float> %47, %v45
  store <4 x float> %v46, <4 x float>* %v
  %48 = load <4 x float>* %v
  %v47 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %48)
  %49 = load <4 x float>* %v
  %v48 = fadd <4 x float> %49, %v47
  store <4 x float> %v48, <4 x float>* %v
  %50 = load <4 x float>* %v
  %v49 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %50)
  %51 = load <4 x float>* %v
  %v50 = fadd <4 x float> %51, %v49
  store <4 x float> %v50, <4 x float>* %v
  %52 = load <4 x float>* %v
  %v51 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %52)
  %53 = load <4 x float>* %v
  %v52 = fadd <4 x float> %53, %v51
  store <4 x float> %v52, <4 x float>* %v
  %54 = load <4 x float>* %v
  %55 = load <4 x float>* %v
  %56 = frem <4 x float> %54, %55
  %57 = load <4 x float>* %v
  %v53 = fadd <4 x float> %57, %56
  store <4 x float> %v53, <4 x float>* %v
  %58 = load <4 x float>* %v
  %59 = load <4 x float>* %v
  %60 = extractelement <4 x float> %59, i32 0
  %61 = insertelement <4 x float> undef, float %60, i32 0
  %62 = insertelement <4 x float> %61, float %60, i32 1
  %63 = insertelement <4 x float> %62, float %60, i32 2
  %64 = insertelement <4 x float> %63, float %60, i32 3
  %65 = frem <4 x float> %58, %64
  %66 = load <4 x float>* %v
  %v54 = fadd <4 x float> %66, %65
  store <4 x float> %v54, <4 x float>* %v
  %67 = load <4 x float>* %v
  %68 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v55 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %67, <4 x float> %68)
  %69 = load <4 x float>* %v
  %v56 = fadd <4 x float> %69, %v55
  store <4 x float> %v56, <4 x float>* %v
  %70 = load <4 x float>* %v
  %71 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v57 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %70, <4 x float> %71)
  %72 = load <4 x float>* %v
  %v58 = fadd <4 x float> %72, %v57
  store <4 x float> %v58, <4 x float>* %v
  %73 = load <4 x float>* %v
  %74 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %75 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %v59 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %73, <4 x float> %74, <4 x float> %75)
  %76 = load <4 x float>* %v
  %v60 = fadd <4 x float> %76, %v59
  store <4 x float> %v60, <4 x float>* %v
  %77 = load <4 x float>* %v
  %78 = load <4 x float>* %v
  %79 = load <4 x float>* %v
  %v61 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %77, <4 x float> %78, <4 x float> %79)
  %80 = load <4 x float>* %v
  %v62 = fadd <4 x float> %80, %v61
  store <4 x float> %v62, <4 x float>* %v
  %81 = load <4 x float>* %v
  %82 = load <4 x float>* %v
  %v63 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %81, <4 x float> %82)
  %83 = load <4 x float>* %v
  %v64 = fadd <4 x float> %83, %v63
  store <4 x float> %v64, <4 x float>* %v
  %84 = load <4 x float>* %v
  %85 = load <4 x float>* %v
  %86 = load <4 x float>* %v
  %v65 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %84, <4 x float> %85, <4 x float> %86)
  %87 = load <4 x float>* %v
  %v66 = fadd <4 x float> %87, %v65
  store <4 x float> %v66, <4 x float>* %v
  %88 = load float addrspace(2)* @uf, !gla.uniform !4
  %89 = load <4 x float>* %v
  %v67 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %88, <4 x float> %89)
  %90 = load <4 x float>* %v
  %v68 = fadd <4 x float> %90, %v67
  store <4 x float> %v68, <4 x float>* %v
  %91 = load float addrspace(2)* @uf, !gla.uniform !4
  %92 = load float addrspace(2)* @uf, !gla.uniform !4
  %93 = load <4 x float>* %v
  %v69 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %91, float %92, <4 x float> %93)
  %94 = load <4 x float>* %v
  %v70 = fadd <4 x float> %94, %v69
  store <4 x float> %v70, <4 x float>* %v
  %95 = load <4 x float>* %v
  %v71 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %95)
  %96 = load <4 x float>* %v
  %v72 = fadd <4 x float> %96, %v71
  store <4 x float> %v72, <4 x float>* %v
  %97 = load <4 x float>* %v
  %98 = load <4 x float>* %v
  %99 = load <4 x float>* %v
  %v73 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %97, <4 x float> %98, <4 x float> %99)
  %100 = load <4 x float>* %v
  %v74 = fadd <4 x float> %100, %v73
  store <4 x float> %v74, <4 x float>* %v
  %101 = load <4 x float>* %v
  %102 = load <4 x float>* %v
  %v75 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %101, <4 x float> %102)
  %103 = load <4 x float>* %v
  %v76 = fadd <4 x float> %103, %v75
  store <4 x float> %v76, <4 x float>* %v
  %104 = load <4 x float>* %v
  %105 = load <4 x float>* %v
  %106 = load float addrspace(2)* @uf, !gla.uniform !4
  %v77 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %104, <4 x float> %105, float %106)
  %107 = load <4 x float>* %v
  %v78 = fadd <4 x float> %107, %v77
  store <4 x float> %v78, <4 x float>* %v
  %108 = load <4 x float>* %v
  %v79 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %108)
  %109 = load <4 x float>* %v
  %v80 = fadd <4 x float> %109, %v79
  store <4 x float> %v80, <4 x float>* %v
  %110 = load <4 x float>* %v
  %v81 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %110)
  %111 = load <4 x float>* %v
  %v82 = fadd <4 x float> %111, %v81
  store <4 x float> %v82, <4 x float>* %v
  %112 = load <4 x float>* %v
  %v83 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %112)
  %113 = load <4 x float>* %v
  %v84 = fadd <4 x float> %113, %v83
  store <4 x float> %v84, <4 x float>* %v
  %114 = load <4 x float>* %v
  %115 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %116 = fcmp olt <4 x float> %114, %115
  %b86 = call i1 @llvm.gla.any.v4i1(<4 x i1> %116)
  store i1 %b86, i1* %b
  %117 = load i1* %b
  %118 = load <4 x float>* %v
  %119 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %120 = fcmp ole <4 x float> %118, %119
  %b87 = call i1 @llvm.gla.any.v4i1(<4 x i1> %120)
  %b88 = and i1 %117, %b87
  store i1 %b88, i1* %b
  %121 = load i1* %b
  %122 = load <4 x float>* %v
  %123 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %124 = fcmp ogt <4 x float> %122, %123
  %b89 = call i1 @llvm.gla.any.v4i1(<4 x i1> %124)
  %b90 = and i1 %121, %b89
  store i1 %b90, i1* %b
  %125 = load i1* %b
  %126 = load <4 x float>* %v
  %127 = load <4 x float> addrspace(2)* @uv4, !gla.uniform !1
  %128 = fcmp oge <4 x float> %126, %127
  %b91 = call i1 @llvm.gla.any.v4i1(<4 x i1> %128)
  %b92 = and i1 %125, %b91
  store i1 %b92, i1* %b
  %129 = load i1* %b
  %130 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %131 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %132 = icmp eq <4 x i1> %130, %131
  %b93 = call i1 @llvm.gla.any.v4i1(<4 x i1> %132)
  %b94 = and i1 %129, %b93
  store i1 %b94, i1* %b
  %133 = load i1* %b
  %134 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %135 = load <4 x i1> addrspace(2)* @ub42, !gla.uniform !6
  %136 = icmp ne <4 x i1> %134, %135
  %b95 = call i1 @llvm.gla.any.v4i1(<4 x i1> %136)
  %b96 = and i1 %133, %b95
  store i1 %b96, i1* %b
  %137 = load i1* %b
  %138 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %b97 = call i1 @llvm.gla.any.v4i1(<4 x i1> %138)
  %b98 = and i1 %137, %b97
  store i1 %b98, i1* %b
  %139 = load i1* %b
  %140 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %b99 = call i1 @llvm.gla.all.v4i1(<4 x i1> %140)
  %b100 = and i1 %139, %b99
  store i1 %b100, i1* %b
  %141 = load i1* %b
  %142 = load <4 x i1> addrspace(2)* @ub41, !gla.uniform !5
  %143 = xor <4 x i1> %142, <i1 true, i1 true, i1 true, i1 true>
  %b101 = call i1 @llvm.gla.any.v4i1(<4 x i1> %143)
  %b102 = and i1 %141, %b101
  store i1 %b102, i1* %b
  %144 = load i32* %i
  %145 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %146 = add i32 %144, %145
  %147 = load i32* %i
  %148 = mul i32 %146, %147
  %149 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %150 = sub i32 %148, %149
  %151 = load i32* %i
  %i103 = sdiv i32 %150, %151
  store i32 %i103, i32* %i
  %152 = load i32* %i
  %153 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %i104 = srem i32 %152, %153
  store i32 %i104, i32* %i
  %154 = load i32* %i
  %155 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %156 = icmp eq i32 %154, %155
  %157 = load i32* %i
  %158 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %159 = icmp ne i32 %157, %158
  %160 = load i32* %i
  %161 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %162 = icmp eq i32 %160, %161
  %163 = and i1 %159, %162
  %164 = load i32* %i
  %165 = icmp ne i32 %164, 2
  %166 = xor i1 %163, %165
  %167 = or i1 %156, %166
  br i1 %167, label %then, label %ifmerge

then:                                             ; preds = %entry
  %168 = load i32* %i
  %i105 = add i32 %168, 1
  store i32 %i105, i32* %i
  br label %ifmerge

ifmerge:                                          ; preds = %entry, %then
  %169 = load float addrspace(2)* @uf, !gla.uniform !4
  %170 = load float addrspace(2)* @uf, !gla.uniform !4
  %171 = fadd float %169, %170
  %172 = load float addrspace(2)* @uf, !gla.uniform !4
  %173 = fmul float %171, %172
  %174 = load float addrspace(2)* @uf, !gla.uniform !4
  %175 = fsub float %173, %174
  %176 = load float addrspace(2)* @uf, !gla.uniform !4
  %f106 = fdiv float %175, %176
  store float %f106, float* %f
  %177 = load <4 x float>* %v
  %f107 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %177)
  %178 = load float* %f
  %f108 = fadd float %178, %f107
  store float %f108, float* %f
  %179 = load <4 x float>* %v
  %180 = load <4 x float>* %v
  %f109 = call float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float> %179, <4 x float> %180)
  %181 = load float* %f
  %f110 = fadd float %181, %f109
  store float %f110, float* %f
  %182 = load <4 x float>* %v
  %183 = load <4 x float>* %v
  %f111 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %182, <4 x float> %183)
  %184 = load float* %f
  %f112 = fadd float %184, %f111
  store float %f112, float* %f
  %185 = load float* %f
  %186 = load float addrspace(2)* @uf, !gla.uniform !4
  %187 = fmul float %185, %186
  %188 = load float* %f
  %f113 = fadd float %188, %187
  store float %f113, float* %f
  %189 = load <4 x float>* %v
  %190 = extractelement <4 x float> %189, i32 0
  %191 = insertelement <3 x float> undef, float %190, i32 0
  %192 = extractelement <4 x float> %189, i32 1
  %193 = insertelement <3 x float> %191, float %192, i32 1
  %194 = extractelement <4 x float> %189, i32 2
  %195 = insertelement <3 x float> %193, float %194, i32 2
  %196 = load <4 x float>* %v
  %197 = extractelement <4 x float> %196, i32 0
  %198 = insertelement <3 x float> undef, float %197, i32 0
  %199 = extractelement <4 x float> %196, i32 1
  %200 = insertelement <3 x float> %198, float %199, i32 1
  %201 = extractelement <4 x float> %196, i32 2
  %202 = insertelement <3 x float> %200, float %201, i32 2
  %f114 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %195, <3 x float> %202)
  %203 = extractelement <3 x float> %f114, i32 0
  %204 = load float* %f
  %f115 = fadd float %204, %203
  store float %f115, float* %f
  %205 = load float* %f
  %206 = load float addrspace(2)* @uf, !gla.uniform !4
  %207 = fcmp oeq float %205, %206
  %208 = load float* %f
  %209 = load float addrspace(2)* @uf, !gla.uniform !4
  %210 = fcmp one float %208, %209
  %211 = load float* %f
  %212 = fcmp one float %211, 2.000000e+00
  %213 = and i1 %210, %212
  %214 = or i1 %207, %213
  br i1 %214, label %then116, label %ifmerge118

then116:                                          ; preds = %ifmerge
  %215 = load float* %f
  %f117 = fadd float %215, 1.000000e+00
  store float %f117, float* %f
  br label %ifmerge118

ifmerge118:                                       ; preds = %ifmerge, %then116
  %216 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %217 = load i32* %i
  %i119 = and i32 %217, %216
  store i32 %i119, i32* %i
  %218 = load i32* %i
  %i120 = or i32 %218, 66
  store i32 %i120, i32* %i
  %219 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %220 = load i32* %i
  %i121 = xor i32 %220, %219
  store i32 %i121, i32* %i
  %221 = load i32* %i
  %i122 = srem i32 %221, 17
  store i32 %i122, i32* %i
  %222 = load i32* %i
  %i123 = ashr i32 %222, 2
  store i32 %i123, i32* %i
  %223 = load i32 addrspace(2)* @ui, !gla.uniform !3
  %224 = load i32* %i
  %i124 = shl i32 %224, %223
  store i32 %i124, i32* %i
  %225 = load i32* %i
  %i125 = xor i32 %225, -1
  store i32 %i125, i32* %i
  %226 = load i1* %b
  %b126 = xor i1 %226, true
  store i1 %b126, i1* %b
  %227 = load i1* %b
  br i1 %227, label %then127, label %else

then127:                                          ; preds = %ifmerge118
  %228 = load i32* %i
  %229 = sitofp i32 %228 to float
  %230 = load <4 x float>* %gl_FragColor128
  %231 = insertelement <4 x float> undef, float %229, i32 0
  %232 = insertelement <4 x float> %231, float %229, i32 1
  %233 = insertelement <4 x float> %232, float %229, i32 2
  %234 = insertelement <4 x float> %233, float %229, i32 3
  %235 = load float* %f
  %236 = load <4 x float>* %gl_FragColor129
  %237 = insertelement <4 x float> undef, float %235, i32 0
  %238 = insertelement <4 x float> %237, float %235, i32 1
  %239 = insertelement <4 x float> %238, float %235, i32 2
  %240 = insertelement <4 x float> %239, float %235, i32 3
  %241 = fadd <4 x float> %234, %240
  %242 = load <4 x float>* %v
  %gl_FragColor130 = fadd <4 x float> %241, %242
  store <4 x float> %gl_FragColor130, <4 x float>* %gl_FragColor
  br label %ifmerge132

else:                                             ; preds = %ifmerge118
  %gl_FragColor131 = load <4 x float>* %v
  store <4 x float> %gl_FragColor131, <4 x float>* %gl_FragColor
  br label %ifmerge132

ifmerge132:                                       ; preds = %else, %then127
  %gl_FragColor133 = load <4 x float>* %gl_FragColor
  store <4 x float> %gl_FragColor133, <4 x float>* @gl_FragColor
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %ifmerge132
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRadians.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDegrees.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDistance.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}


Bottom IR:
; ModuleID = 'Glslang'

@uv4 = external addrspace(2) constant <4 x float>
@ui = external addrspace(2) constant i32
@uf = external addrspace(2) constant float
@ub41 = external addrspace(2) constant <4 x i1>
@ub42 = external addrspace(2) constant <4 x i1>
@gl_FragColor = global <4 x float> zeroinitializer

define fastcc void @main() {
entry:
  %0 = load <4 x float> addrspace(2)* @uv4, align 16, !gla.uniform !1
  %1 = fmul <4 x float> %0, <float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000, float 0x3F91DF46A0000000>
  %2 = fmul <4 x float> %1, <float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000, float 0x404CA5DC20000000>
  %v4 = fadd <4 x float> %1, %2
  %3 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i5 = mul i32 %3, %3
  %uni = call <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float> %v4)
  %v6 = fadd <4 x float> %uni, %v4
  %v7 = call <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float> %v6)
  %v8 = fadd <4 x float> %v7, %v6
  %v9 = call <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float> %v8)
  %v10 = fadd <4 x float> %v9, %v8
  %v11 = call <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float> %v10)
  %v12 = fadd <4 x float> %v11, %v10
  %v13 = call <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float> %v12)
  %v14 = fadd <4 x float> %v13, %v12
  %v15 = call <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float> %v14)
  %v16 = fadd <4 x float> %v15, %v14
  %v17 = call <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float> %v16)
  %v18 = fadd <4 x float> %v17, %v16
  %v19 = call <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float> %v18)
  %v20 = fadd <4 x float> %v19, %v18
  %v21 = call <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float> %v20)
  %v22 = fadd <4 x float> %v21, %v20
  %v23 = call <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float> %v22)
  %v24 = fadd <4 x float> %v23, %v22
  %v25 = call <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float> %v24)
  %v26 = fadd <4 x float> %v25, %v24
  %v27 = call <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float> %v26)
  %v28 = fadd <4 x float> %v27, %v26
  %v29 = call <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float> %v28, <4 x float> %v28)
  %v30 = fadd <4 x float> %v29, %v28
  %v31 = call <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float> %v30)
  %v32 = fadd <4 x float> %v31, %v30
  %v33 = call <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float> %v32)
  %v34 = fadd <4 x float> %v33, %v32
  %v35 = call <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float> %v34)
  %v36 = fadd <4 x float> %v35, %v34
  %v37 = call <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float> %v36)
  %v38 = fadd <4 x float> %v37, %v36
  %v39 = call <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float> %v38)
  %v40 = fadd <4 x float> %v39, %v38
  %v41 = call <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float> %v40)
  %v42 = fadd <4 x float> %v41, %v40
  %v43 = call <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float> %v42)
  %v44 = fadd <4 x float> %v43, %v42
  %v45 = call <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float> %v44)
  %v46 = fadd <4 x float> %v45, %v44
  %v47 = call <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float> %v46)
  %v48 = fadd <4 x float> %v47, %v46
  %v49 = call <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float> %v48)
  %v50 = fadd <4 x float> %v49, %v48
  %v51 = call <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float> %v50)
  %v52 = fadd <4 x float> %v51, %v50
  %4 = frem <4 x float> %v52, %v52
  %v53 = fadd <4 x float> %4, %v52
  %5 = call <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float> %v53, <4 x i32> zeroinitializer)
  %6 = frem <4 x float> %v53, %5
  %v54 = fadd <4 x float> %6, %v53
  %v55 = call <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float> %v54, <4 x float> %0)
  %v56 = fadd <4 x float> %v55, %v54
  %v57 = call <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float> %v56, <4 x float> %0)
  %v58 = fadd <4 x float> %v57, %v56
  %v59 = call <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float> %v58, <4 x float> %0, <4 x float> %0)
  %v60 = fadd <4 x float> %v59, %v58
  %v61 = call <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float> %v60, <4 x float> %v60, <4 x float> %v60)
  %v62 = fadd <4 x float> %v61, %v60
  %v63 = call <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float> %v62, <4 x float> %v62)
  %v64 = fadd <4 x float> %v63, %v62
  %v65 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float> %v64, <4 x float> %v64, <4 x float> %v64)
  %v66 = fadd <4 x float> %v65, %v64
  %7 = load float addrspace(2)* @uf, align 4, !gla.uniform !4
  %v67 = call <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float %7, <4 x float> %v66)
  %v68 = fadd <4 x float> %v66, %v67
  %v69 = call <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float %7, float %7, <4 x float> %v68)
  %v70 = fadd <4 x float> %v68, %v69
  %v71 = call <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float> %v70)
  %v72 = fadd <4 x float> %v70, %v71
  %v73 = call <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float> %v72, <4 x float> %v72, <4 x float> %v72)
  %v74 = fadd <4 x float> %v72, %v73
  %v75 = call <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float> %v74, <4 x float> %v74)
  %v76 = fadd <4 x float> %v74, %v75
  %v77 = call <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float> %v76, <4 x float> %v76, float %7)
  %v78 = fadd <4 x float> %v76, %v77
  %v79 = call <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float> %v78)
  %v80 = fadd <4 x float> %v78, %v79
  %v81 = call <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float> %v80)
  %v82 = fadd <4 x float> %v80, %v81
  %v83 = call <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float> %v82)
  %v84 = fadd <4 x float> %v82, %v83
  %8 = call <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float> %v84, <3 x i32> <i32 0, i32 1, i32 2>)
  %9 = fcmp olt <4 x float> %v84, %0
  %b86 = call i1 @llvm.gla.any.v4i1(<4 x i1> %9)
  %10 = fcmp ole <4 x float> %v84, %0
  %b87 = call i1 @llvm.gla.any.v4i1(<4 x i1> %10)
  %b88 = and i1 %b86, %b87
  %11 = fcmp ogt <4 x float> %v84, %0
  %b89 = call i1 @llvm.gla.any.v4i1(<4 x i1> %11)
  %b90 = and i1 %b88, %b89
  %12 = fcmp oge <4 x float> %v84, %0
  %b91 = call i1 @llvm.gla.any.v4i1(<4 x i1> %12)
  %b92 = and i1 %b90, %b91
  %13 = load <4 x i1> addrspace(2)* @ub41, align 4, !gla.uniform !5
  %14 = load <4 x i1> addrspace(2)* @ub42, align 4, !gla.uniform !6
  %15 = icmp eq <4 x i1> %13, %14
  %b93 = call i1 @llvm.gla.any.v4i1(<4 x i1> %15)
  %b94 = and i1 %b92, %b93
  %16 = icmp ne <4 x i1> %13, %14
  %b95 = call i1 @llvm.gla.any.v4i1(<4 x i1> %16)
  %b96 = and i1 %b94, %b95
  %b97 = call i1 @llvm.gla.any.v4i1(<4 x i1> %13)
  %b98 = and i1 %b96, %b97
  %b99 = call i1 @llvm.gla.all.v4i1(<4 x i1> %13)
  %b100 = and i1 %b98, %b99
  %17 = xor <4 x i1> %13, <i1 true, i1 true, i1 true, i1 true>
  %b101 = call i1 @llvm.gla.any.v4i1(<4 x i1> %17)
  %b102 = and i1 %b100, %b101
  %18 = add i32 %i5, %3
  %19 = mul i32 %18, %i5
  %20 = sub i32 %19, %3
  %i103 = sdiv i32 %20, %i5
  %i104 = srem i32 %i103, %3
  %21 = icmp eq i32 %i104, 2
  %i105 = add i32 %i104, 1
  %.i105 = select i1 %21, i32 0, i32 %i105
  %22 = fadd float %7, %7
  %23 = fmul float %7, %22
  %24 = fsub float %23, %7
  %f106 = fdiv float %24, %7
  %f107 = call float @llvm.gla.fLength.f32.v4f32(<4 x float> %v84)
  %f108 = fadd float %f106, %f107
  %f111 = call float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float> %v84, <4 x float> %v84)
  %f112 = fadd float %f108, %f111
  %25 = fmul float %7, %f112
  %f113 = fadd float %f112, %25
  %f114 = call <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float> %8, <3 x float> %8)
  %26 = extractelement <3 x float> %f114, i32 0
  %f115 = fadd float %26, %f113
  %27 = fcmp oeq float %f115, %7
  %28 = fcmp one float %f115, %7
  %29 = fcmp one float %f115, 2.000000e+00
  %30 = and i1 %28, %29
  %31 = or i1 %27, %30
  %f117 = fadd float %f115, 1.000000e+00
  %select134 = select i1 %31, float %f117, float %f115
  %32 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %select134, <4 x i32> zeroinitializer)
  %33 = load i32 addrspace(2)* @ui, align 4, !gla.uniform !3
  %i119 = and i32 %33, %.i105
  %i120 = or i32 %i119, 66
  %i121 = xor i32 %i120, %33
  %i122 = srem i32 %i121, 17
  %i123 = ashr i32 %i122, 2
  %i124 = shl i32 %i123, %33
  %i125 = xor i32 %i124, -1
  %34 = sitofp i32 %i125 to float
  %35 = call <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float %34, <4 x i32> zeroinitializer)
  %36 = fadd <4 x float> %35, %32
  %gl_FragColor130 = fadd <4 x float> %v84, %36
  %select = select i1 %b102, <4 x float> %v84, <4 x float> %gl_FragColor130
  store <4 x float> %select, <4 x float>* @gl_FragColor, align 16
  br label %stage-epilogue

stage-epilogue:                                   ; preds = %entry
  br label %stage-exit

stage-exit:                                       ; preds = %stage-epilogue
  ret void
}

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsin.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcos.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtan.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fTanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAsinh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAcosh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAtanh.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fPow.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fExp2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fLog2.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fInverseSqrt.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fAbs.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSign.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFloor.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fCeiling.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFraction.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMin.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMax.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fClamp.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fMix.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fStep.v4f32.f32.v4f32(float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSmoothStep.v4f32.f32.f32.v4f32(float, float, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fNormalize.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFaceForward.v4f32.v4f32.v4f32.v4f32(<4 x float>, <4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fReflect.v4f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fRefract.v4f32.v4f32.v4f32.f32(<4 x float>, <4 x float>, float) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdx.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fDFdy.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fFilterWidth.v4f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.any.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare i1 @llvm.gla.all.v4i1(<4 x i1>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fLength.f32.v4f32(<4 x float>) #0

; Function Attrs: nounwind readnone
declare float @llvm.gla.fDot4.f32.v4f32.v4f32(<4 x float>, <4 x float>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fCross.v3f32.v3f32.v3f32(<3 x float>, <3 x float>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.v4f32.v4i32(<4 x float>, <4 x i32>) #0

; Function Attrs: nounwind readnone
declare <3 x float> @llvm.gla.fSwizzle.v3f32.v4f32.v3i32(<4 x float>, <3 x i32>) #0

; Function Attrs: nounwind readnone
declare <4 x float> @llvm.gla.fSwizzle.v4f32.f32.v4i32(float, <4 x i32>) #0

attributes #0 = { nounwind readnone }

!gla.entrypoint = !{!0}
!gla.uniforms = !{!1, !3, !4, !5, !6, !7, !8}
!gla.outputs = !{!9}
!gla.noStaticUse = !{!7, !8}

!0 = metadata !{metadata !"main", i32 15}
!1 = metadata !{metadata !"uv4", i32 12, <4 x float>* @uv4_typeProxy, metadata !2}
!2 = metadata !{i32 0, i32 0, i32 1024, null}
!3 = metadata !{metadata !"ui", i32 12, i32* @ui_typeProxy, metadata !2}
!4 = metadata !{metadata !"uf", i32 12, float* @uf_typeProxy, metadata !2}
!5 = metadata !{metadata !"ub41", i32 12, <4 x i1>* @ub41_typeProxy, metadata !2}
!6 = metadata !{metadata !"ub42", i32 12, <4 x i1>* @ub42_typeProxy, metadata !2}
!7 = metadata !{metadata !"uiv4", i32 12, <4 x i32>* @uiv4_typeProxy, metadata !2}
!8 = metadata !{metadata !"ub", i32 12, i1* @ub_typeProxy, metadata !2}
!9 = metadata !{metadata !"gl_FragColor", i32 7, <4 x float>* @gl_FragColor_typeProxy, metadata !10}
!10 = metadata !{i32 0, i32 0, i32 1024, null, i32 0}
#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 C_vssely1 = vec4(0.0174533);
const vec4 C_4bmlfm = vec4(57.2958);
const int C_2 = 2;
const int C_1 = 1;
const int C_0 = 0;
const float C_2d0 = 2.0;
const float C_1d0 = 1.0;
const int C_66 = 66;
const int C_17 = 17;

void main()
{
	vec4 H_hgy73b1 = uv4 * C_vssely1;
	vec4 H_rrtr9n = H_hgy73b1 * C_4bmlfm;
	vec4 H_2u0bi2 = H_hgy73b1 + H_rrtr9n;
	int H_h8ktht1 = ui * ui;
	vec4 uni = sin(H_2u0bi2);
	vec4 H_jqi9qw1 = H_2u0bi2 + uni;
	vec4 H_0rp3gf1 = cos(H_jqi9qw1);
	vec4 H_9vdfqt = H_0rp3gf1 + H_jqi9qw1;
	vec4 H_wl578r1 = tan(H_9vdfqt);
	vec4 H_yxt4l41 = H_9vdfqt + H_wl578r1;
	vec4 H_c1j58i = asin(H_yxt4l41);
	vec4 H_g1c7l6 = H_c1j58i + H_yxt4l41;
	vec4 H_f1quob1 = acos(H_g1c7l6);
	vec4 H_x6kmuu1 = H_f1quob1 + H_g1c7l6;
	vec4 H_6al3re1 = atan(H_x6kmuu1);
	vec4 H_pfswwj = H_6al3re1 + H_x6kmuu1;
	vec4 H_oms0zh1 = sinh(H_pfswwj);
	vec4 H_bn09q51 = H_oms0zh1 + H_pfswwj;
	vec4 H_aghx9o = cosh(H_bn09q51);
	vec4 H_2br8n4 = H_aghx9o + H_bn09q51;
	vec4 H_40vce2 = tanh(H_2br8n4);
	vec4 H_ina7fw = H_2br8n4 + H_40vce2;
	vec4 H_ef89p9 = asinh(H_ina7fw);
	vec4 H_vblhcg = H_ef89p9 + H_ina7fw;
	vec4 H_3feejp1 = acosh(H_vblhcg);
	vec4 H_k0rko11 = H_3feejp1 + H_vblhcg;
	vec4 H_49cny = atanh(H_k0rko11);
	vec4 H_knxf5j = H_49cny + H_k0rko11;
	vec4 H_y0jli01 = pow(H_knxf5j, H_knxf5j);
	vec4 H_bf27ak = H_knxf5j + H_y0jli01;
	vec4 H_xrl7vd = exp(H_bf27ak);
	vec4 H_id6sg61 = H_bf27ak + H_xrl7vd;
	vec4 H_vn085z = log(H_id6sg61);
	vec4 H_jew9k = H_id6sg61 + H_vn085z;
	vec4 H_aphqlb1 = exp2(H_jew9k);
	vec4 H_7us9ch = H_aphqlb1 + H_jew9k;
	vec4 H_oo9eka1 = log2(H_7us9ch);
	vec4 H_ic39w31 = H_7us9ch + H_oo9eka1;
	vec4 H_sdhrvk = sqrt(H_ic39w31);
	vec4 H_zhv89e1 = H_ic39w31 + H_sdhrvk;
	vec4 H_qe4dhf = inversesqrt(H_zhv89e1);
	vec4 H_3uovp9 = H_qe4dhf + H_zhv89e1;
	vec4 H_l4btqc1 = abs(H_3uovp9);
	vec4 H_drkj1k1 = H_3uovp9 + H_l4btqc1;
	vec4 H_03wpb41 = sign(H_drkj1k1);
	vec4 H_3s7mt51 = H_03wpb41 + H_drkj1k1;
	vec4 H_dbzw8l = floor(H_3s7mt51);
	vec4 H_zogea1 = H_3s7mt51 + H_dbzw8l;
	vec4 H_vx6wk5 = ceil(H_zogea1);
	vec4 H_sukbt41 = H_vx6wk5 + H_zogea1;
	vec4 H_nocf5c = fract(H_sukbt41);
	vec4 H_slrue7 = H_nocf5c + H_sukbt41;
	vec4 H_kuqjea = mod(H_slrue7, H_slrue7);
	vec4 H_brar7k1 = H_kuqjea + H_slrue7;
	vec4 H_uiee6w1 = mod(H_brar7k1, H_brar7k1.xxxx);
	vec4 H_8041qy = H_brar7k1 + H_uiee6w1;
	vec4 H_1i5g17 = min(H_8041qy, uv4);
	vec4 H_9aie7r1 = H_1i5g17 + H_8041qy;
	vec4 H_ec18uy1 = max(H_9aie7r1, uv4);
	vec4 H_4kmq4j1 = H_9aie7r1 + H_ec18uy1;
	vec4 H_o0ojpt1 = clamp(H_4kmq4j1, uv4, uv4);
	vec4 H_72no261 = H_4kmq4j1 + H_o0ojpt1;
	vec4 H_is0u2s = mix(H_72no261, H_72no261, H_72no261);
	vec4 H_tytg12 = H_72no261 + H_is0u2s;
	vec4 H_0qrxik = step(H_tytg12, H_tytg12);
	vec4 H_wz5n5h = H_0qrxik + H_tytg12;
	vec4 H_ob7ze7 = smoothstep(H_wz5n5h, H_wz5n5h, H_wz5n5h);
	vec4 H_x2zgdf1 = H_ob7ze7 + H_wz5n5h;
	vec4 H_my1n1j1 = step(uf, H_x2zgdf1);
	vec4 H_5czyiz = H_my1n1j1 + H_x2zgdf1;
	vec4 H_jnf9m4 = smoothstep(uf, uf, H_5czyiz);
	vec4 H_wz2mq41 = H_5czyiz + H_jnf9m4;
	vec4 H_mt2btd = normalize(H_wz2mq41);
	vec4 H_bwl1ia1 = H_mt2btd + H_wz2mq41;
	vec4 H_6t6trb = faceforward(H_bwl1ia1, H_bwl1ia1, H_bwl1ia1);
	vec4 H_vlzry21 = H_6t6trb + H_bwl1ia1;
	vec4 H_r9qogq = reflect(H_vlzry21, H_vlzry21);
	vec4 H_j8w6fe1 = H_r9qogq + H_vlzry21;
	vec4 H_usy7m3 = refract(H_j8w6fe1, H_j8w6fe1, uf);
	vec4 H_9t9k1s1 = H_j8w6fe1 + H_usy7m3;
	vec4 H_njzidd = dFdx(H_9t9k1s1);
	vec4 H_r7pm4g = H_9t9k1s1 + H_njzidd;
	vec4 H_78sb82 = dFdy(H_r7pm4g);
	vec4 H_bxno3 = H_78sb82 + H_r7pm4g;
	vec4 H_xoecm3 = fwidth(H_bxno3);
	vec4 H_lfd10t1 = H_bxno3 + H_xoecm3;
	bvec4 H_onwjwl1 = lessThan(H_lfd10t1, uv4);
	bool H_r5e40g1 = any(H_onwjwl1);
	bvec4 H_e65lwf = lessThanEqual(H_lfd10t1, uv4);
	bool H_gvb9bi1 = any(H_e65lwf);
	bool H_zjnx131 = H_r5e40g1 && H_gvb9bi1;
	bvec4 H_9dk8xt1 = greaterThan(H_lfd10t1, uv4);
	bool H_a2o37e1 = any(H_9dk8xt1);
	bool H_sf0eh91 = H_zjnx131 && H_a2o37e1;
	bvec4 H_l9fmhx = greaterThanEqual(H_lfd10t1, uv4);
	bool H_rfrsbm = any(H_l9fmhx);
	bool H_f0zcop = H_sf0eh91 && H_rfrsbm;
	bvec4 H_vlocan1 = equal(ub41, ub42);
	bool H_by51mk1 = any(H_vlocan1);
	bool H_vl8ftk = H_f0zcop && H_by51mk1;
	bvec4 H_e6ku4t1 = notEqual(ub41, ub42);
	bool H_rjqzlx = any(H_e6ku4t1);
	bool H_vpk2be1 = H_vl8ftk && H_rjqzlx;
	bool H_u0wve91 = any(ub41);
	bool H_tlmzr21 = H_vpk2be1 && H_u0wve91;
	bool H_f4b5uh1 = all(ub41);
	bool H_8hjxpc1 = H_tlmzr21 && H_f4b5uh1;
	bvec4 H_db60wu = not(ub41);
	bool H_hpec3a1 = any(H_db60wu);
	bool H_ehd104 = H_8hjxpc1 && H_hpec3a1;
	int H_ngz3vc1 = H_h8ktht1 + ui;
	int H_l1vuw31 = H_h8ktht1 * H_ngz3vc1;
	int H_2knscd = H_l1vuw31 - ui;
	int H_rq4ows = H_2knscd / H_h8ktht1;
	int H_xtc1vg = H_rq4ows % ui;
	bool H_ry3ksp = H_xtc1vg == C_2;
	int H_3j3nrk1 = H_xtc1vg + C_1;
	int _L = H_ry3ksp ? C_0 : H_3j3nrk1;
	float H_6ra9oe1 = uf + uf;
	float H_eccx591 = H_6ra9oe1 * uf;
	float H_my73qz = H_eccx591 - uf;
	float H_1umaut = H_my73qz / uf;
	float H_dur145 = length(H_lfd10t1);
	float H_ojhehp = H_1umaut + H_dur145;
	float H_db7xvs = dot(H_lfd10t1, H_lfd10t1);
	float H_ywvhdx = H_db7xvs + H_ojhehp;
	float H_rgdi2i = H_ywvhdx * uf;
	float H_ndekpu = H_rgdi2i + H_ywvhdx;
	vec3 H_8jxrqf = cross(H_lfd10t1.xyz, H_lfd10t1.xyz);
	float H_k7563j1 = H_8jxrqf.x + H_ndekpu;
	bool H_6ne9xg1 = H_k7563j1 == uf;
	bool H_y3lk171 = H_k7563j1 != uf;
	bool H_ztdus6 = H_k7563j1 != C_2d0;
	bool H_tn1fc51 = H_y3lk171 && H_ztdus6;
	bool H_tjj7jy = H_6ne9xg1 || H_tn1fc51;
	float H_jb3bph1 = H_k7563j1 + C_1d0;
	float select = H_tjj7jy ? H_jb3bph1 : H_k7563j1;
	vec4 H_c1z5nn = vec4(select);
	int H_sigq8q1 = ui & _L;
	int H_s9dupe1 = H_sigq8q1 | C_66;
	int H_dz351k1 = H_s9dupe1 ^ ui;
	int H_8w7dri1 = H_dz351k1 % C_17;
	int H_qlaxc41 = H_8w7dri1 >> C_2;
	int H_sf9rny = H_qlaxc41 << ui;
	int H_8iiwvi1 = ~(H_sf9rny);
	float H_yrfrlx1 = float(H_8iiwvi1);
	vec4 H_x2iwni1 = vec4(H_yrfrlx1);
	vec4 H_hfe3lx = H_c1z5nn + H_x2iwni1;
	vec4 Ll_FragColor1 = H_hfe3lx + H_lfd10t1;
	vec4 select1 = H_ehd104 ? H_lfd10t1 : Ll_FragColor1;
	gl_FragColor = select1;
	
}

#version 130
// LunarGOO output
uniform vec4 uv4;
uniform int ui;
uniform float uf;
uniform bvec4 ub41;
uniform bvec4 ub42;
uniform ivec4 uiv4;
uniform bool ub;
const vec4 C_vssely1 = vec4(0.0174533);
const vec4 C_4bmlfm = vec4(57.2958);
const int C_2 = 2;
const int C_1 = 1;
const int C_0 = 0;
const float C_2d0 = 2.0;
const float C_1d0 = 1.0;
const int C_66 = 66;
const int C_17 = 17;

void main()
{
	vec4 H_hgy73b = uv4 * C_vssely1;
	vec4 H_rrtr9n = H_hgy73b * C_4bmlfm;
	vec4 H_2u0bi = H_hgy73b + H_rrtr9n;
	int H_h8ktht = ui * ui;
	vec4 uni = sin(H_2u0bi);
	vec4 H_jqi9qw = H_2u0bi + uni;
	vec4 H_0rp3gf = cos(H_jqi9qw);
	vec4 H_9vdfqt = H_0rp3gf + H_jqi9qw;
	vec4 H_wl578r = tan(H_9vdfqt);
	vec4 H_yxt4l = H_9vdfqt + H_wl578r;
	vec4 H_c1j58i = asin(H_yxt4l);
	vec4 H_g1c7l = H_c1j58i + H_yxt4l;
	vec4 H_f1quob = acos(H_g1c7l);
	vec4 H_x6kmuu = H_f1quob + H_g1c7l;
	vec4 H_6al3re = atan(H_x6kmuu);
	vec4 H_pfswwj = H_6al3re + H_x6kmuu;
	vec4 H_oms0zh = sinh(H_pfswwj);
	vec4 H_bn09q = H_oms0zh + H_pfswwj;
	vec4 H_aghx9o = cosh(H_bn09q);
	vec4 H_2br8n = H_aghx9o + H_bn09q;
	vec4 H_40vce = tanh(H_2br8n);
	vec4 H_ina7fw = H_2br8n + H_40vce;
	vec4 H_ef89p = asinh(H_ina7fw);
	vec4 H_vblhcg = H_ef89p + H_ina7fw;
	vec4 H_3feejp = acosh(H_vblhcg);
	vec4 H_k0rko = H_3feejp + H_vblhcg;
	vec4 H_49cny = atanh(H_k0rko);
	vec4 H_knxf5j = H_49cny + H_k0rko;
	vec4 H_y0jli = pow(H_knxf5j, H_knxf5j);
	vec4 H_bf27ak = H_knxf5j + H_y0jli;
	vec4 H_xrl7vd = exp(H_bf27ak);
	vec4 H_id6sg = H_bf27ak + H_xrl7vd;
	vec4 H_vn085z = log(H_id6sg);
	vec4 H_jew9k = H_id6sg + H_vn085z;
	vec4 H_aphqlb = exp2(H_jew9k);
	vec4 H_7us9ch = H_aphqlb + H_jew9k;
	vec4 H_oo9eka = log2(H_7us9ch);
	vec4 H_ic39w = H_7us9ch + H_oo9eka;
	vec4 H_sdhrvk = sqrt(H_ic39w);
	vec4 H_zhv89e = H_ic39w + H_sdhrvk;
	vec4 H_qe4dhf = inversesqrt(H_zhv89e);
	vec4 H_3uovp = H_qe4dhf + H_zhv89e;
	vec4 H_l4btqc = abs(H_3uovp);
	vec4 H_drkj1k = H_3uovp + H_l4btqc;
	vec4 H_03wpb = sign(H_drkj1k);
	vec4 H_3s7mt = H_03wpb + H_drkj1k;
	vec4 H_dbzw8l = floor(H_3s7mt);
	vec4 H_zogea = H_3s7mt + H_dbzw8l;
	vec4 H_vx6wk = ceil(H_zogea);
	vec4 H_sukbt = H_vx6wk + H_zogea;
	vec4 H_nocf5c = fract(H_sukbt);
	vec4 H_slrue = H_nocf5c + H_sukbt;
	vec4 H_kuqjea = mod(H_slrue, H_slrue);
	vec4 H_brar7k = H_kuqjea + H_slrue;
	vec4 H_uiee6w = mod(H_brar7k, H_brar7k.xxxx);
	vec4 H_8041qy = H_brar7k + H_uiee6w;
	vec4 H_1i5g = min(H_8041qy, uv4);
	vec4 H_9aie7r = H_1i5g + H_8041qy;
	vec4 H_ec18uy = max(H_9aie7r, uv4);
	vec4 H_4kmq4j = H_9aie7r + H_ec18uy;
	vec4 H_o0ojpt = clamp(H_4kmq4j, uv4, uv4);
	vec4 H_72no = H_4kmq4j + H_o0ojpt;
	vec4 H_is0u2s = mix(H_72no, H_72no, H_72no);
	vec4 H_tytg = H_72no + H_is0u2s;
	vec4 H_0qrxik = step(H_tytg, H_tytg);
	vec4 H_wz5n5h = H_0qrxik + H_tytg;
	vec4 H_ob7ze = smoothstep(H_wz5n5h, H_wz5n5h, H_wz5n5h);
	vec4 H_x2zgdf = H_ob7ze + H_wz5n5h;
	vec4 H_my1n1j = step(uf, H_x2zgdf);
	vec4 H_5czyiz = H_my1n1j + H_x2zgdf;
	vec4 H_jnf9m = smoothstep(uf, uf, H_5czyiz);
	vec4 H_wz2mq = H_5czyiz + H_jnf9m;
	vec4 H_mt2btd = normalize(H_wz2mq);
	vec4 H_bwl1ia = H_mt2btd + H_wz2mq;
	vec4 H_6t6trb = faceforward(H_bwl1ia, H_bwl1ia, H_bwl1ia);
	vec4 H_vlzry = H_6t6trb + H_bwl1ia;
	vec4 H_r9qogq = reflect(H_vlzry, H_vlzry);
	vec4 H_j8w6fe = H_r9qogq + H_vlzry;
	vec4 H_usy7m = refract(H_j8w6fe, H_j8w6fe, uf);
	vec4 H_9t9k1s = H_j8w6fe + H_usy7m;
	vec4 H_njzidd = dFdx(H_9t9k1s);
	vec4 H_r7pm4g = H_9t9k1s + H_njzidd;
	vec4 H_78sb = dFdy(H_r7pm4g);
	vec4 H_bxno = H_78sb + H_r7pm4g;
	vec4 H_xoecm = fwidth(H_bxno);
	vec4 H_lfd10t = H_bxno + H_xoecm;
	bvec4 H_onwjwl = lessThan(H_lfd10t, uv4);
	bool H_r5e40g = any(H_onwjwl);
	bvec4 H_e65lwf = lessThanEqual(H_lfd10t, uv4);
	bool H_gvb9bi = any(H_e65lwf);
	bool H_zjnx = H_r5e40g && H_gvb9bi;
	bvec4 H_9dk8xt = greaterThan(H_lfd10t, uv4);
	bool H_a2o37e = any(H_9dk8xt);
	bool H_sf0eh = H_zjnx && H_a2o37e;
	bvec4 H_l9fmhx = greaterThanEqual(H_lfd10t, uv4);
	bool H_rfrsbm = any(H_l9fmhx);
	bool H_f0zcop = H_sf0eh && H_rfrsbm;
	bvec4 H_vlocan = equal(ub41, ub42);
	bool H_by51mk = any(H_vlocan);
	bool H_vl8ftk = H_f0zcop && H_by51mk;
	bvec4 H_e6ku4t = notEqual(ub41, ub42);
	bool H_rjqzlx = any(H_e6ku4t);
	bool H_vpk2be = H_vl8ftk && H_rjqzlx;
	bool H_u0wve = any(ub41);
	bool H_tlmzr = H_vpk2be && H_u0wve;
	bool H_f4b5uh = all(ub41);
	bool H_8hjxpc = H_tlmzr && H_f4b5uh;
	bvec4 H_db60wu = not(ub41);
	bool H_hpec3a = any(H_db60wu);
	bool H_ehd = H_8hjxpc && H_hpec3a;
	int H_ngz3vc = H_h8ktht + ui;
	int H_l1vuw = H_h8ktht * H_ngz3vc;
	int H_2knscd = H_l1vuw - ui;
	int H_rq4ows = H_2knscd / H_h8ktht;
	int H_xtc1vg = H_rq4ows % ui;
	bool H_ry3ksp = H_xtc1vg == C_2;
	int H_3j3nrk = H_xtc1vg + C_1;
	int _L = H_ry3ksp ? C_0 : H_3j3nrk;
	float H_6ra9oe = uf + uf;
	float H_eccx = H_6ra9oe * uf;
	float H_my73qz = H_eccx - uf;
	float H_1umaut = H_my73qz / uf;
	float H_dur = length(H_lfd10t);
	float H_ojhehp = H_1umaut + H_dur;
	float H_db7xvs = dot(H_lfd10t, H_lfd10t);
	float H_ywvhdx = H_db7xvs + H_ojhehp;
	float H_rgdi2i = H_ywvhdx * uf;
	float H_ndekpu = H_rgdi2i + H_ywvhdx;
	vec3 H_8jxrqf = cross(H_lfd10t.xyz, H_lfd10t.xyz);
	float H_k7563j = H_8jxrqf.x + H_ndekpu;
	bool H_6ne9xg = H_k7563j == uf;
	bool H_y3lk = H_k7563j != uf;
	bool H_ztdus = H_k7563j != C_2d0;
	bool H_tn1fc = H_y3lk && H_ztdus;
	bool H_tjj7jy = H_6ne9xg || H_tn1fc;
	float H_jb3bph = H_k7563j + C_1d0;
	float select = H_tjj7jy ? H_jb3bph : H_k7563j;
	vec4 H_c1z5nn = vec4(select);
	int H_sigq8q = ui & _L;
	int H_s9dupe = H_sigq8q | C_66;
	int H_dz351k = H_s9dupe ^ ui;
	int H_8w7dri = H_dz351k % C_17;
	int H_qlaxc = H_8w7dri >> C_2;
	int H_sf9rny = H_qlaxc << ui;
	int H_8iiwvi = ~(H_sf9rny);
	float H_yrfrlx = float(H_8iiwvi);
	vec4 H_upvu3e = vec4(H_yrfrlx);
	vec4 H_hfe3lx = H_c1z5nn + H_upvu3e;
	vec4 Ll_FragColor = H_hfe3lx + H_lfd10t;
	vec4 select1 = H_ehd ? H_lfd10t : Ll_FragColor;
	gl_FragColor = select1;
	
}

